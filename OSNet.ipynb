{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbfd62b",
   "metadata": {},
   "source": [
    "安装mindspore、mindvision\n",
    "\n",
    "https://www.mindspore.cn/install\n",
    "\n",
    "https://mindspore.cn/vision/docs/zh-CN/r0.1/mindvision_install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3175bf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MindSpore version:  1.8.1\n",
      "The result of multiplication calculation is correct, MindSpore has been installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "mindspore.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e94c3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image\n",
    "import warnings #simplify\n",
    "\n",
    "\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.common import set_seed\n",
    "from mindspore import Tensor, Model\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor,\\\n",
    "                                      TimeMonitor, SummaryCollector\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.dataset.vision import Resize, Rescale, Normalize, HWC2CHW, RandomHorizontalFlip, RandomErasing\n",
    "from mindspore.dataset.transforms import Compose\n",
    "from mindspore.common.initializer import initializer, HeNormal\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2019b4f",
   "metadata": {},
   "source": [
    "# OSNet行人重识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94569a68",
   "metadata": {},
   "source": [
    "## 任务简介"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f89676ef",
   "metadata": {},
   "source": [
    "![reid.png](./img/reid.png)\n",
    "\n",
    "行人重识别是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术，通常被认为是一个图像检索的子问题。在监控视频中，由于相机分辨率和拍摄角度的缘故，通常无法得到高质量的人脸图片。当人脸识别失效的情况下，ReID就成为了人物身份识别的重要替代技术。\n",
    "行人重识别的数据集通常是通过人工标注或者检测算法得到的行人图片。数据集分为训练集、验证集、Query、Gallery。在训练集上进行训练得到的模型对Query与Gallery中的图片分别提取特征并计算相似度。对于每个Query，在Gallery中会找出前N个与其相似的图片。训练、测试中人物身份不重复。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92335564",
   "metadata": {},
   "source": [
    "## OSNet简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df73fee",
   "metadata": {},
   "source": [
    "![schematic](./img/schematic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78d0f6",
   "metadata": {},
   "source": [
    "首先需要理解omni-scale指什么？ReID的关键在于学习判别性特征，本文认为需要提取全方位特征具有判别性，文中解释为是多样化的同质和异质的分块的结合。\n",
    "\n",
    "OSNet有多个分支，每个分支有不同感受野，捕获不同尺度的特征。通过Channel-wise Adaptive Aggregation融合特征，即一个特征聚合模块，可训练且权重与输入动态关联。\n",
    "\n",
    "OSNet是一个轻量级的网络，它可带来以下好处：（1）轻量级网络具有更少的模型参数，不容易过拟合（2）在大型监视应用程序中（例如，使用数千个摄像头的城市范围的监视），ReID的唯一实用方法是在摄像头端执行特征提取。对于设备上的处理，小型ReID网络显然是首选。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888e001",
   "metadata": {},
   "source": [
    "## 模型解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce67712",
   "metadata": {},
   "source": [
    "#### LightConv3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ae25f",
   "metadata": {},
   "source": [
    "![](./img/LightConv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180512a2",
   "metadata": {},
   "source": [
    "（a）为标准的3\\*3卷积，（b）为轻量化的。采用point-wise和depth-wise操作拆分传统的卷积减少参数量和运算量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05c4292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal(shape, mode='fan_out', nonlinearity='relu'):\n",
    "    '''initialize weight of conv2d layer.'''\n",
    "    weight = initializer(HeNormal(mode=mode, nonlinearity=nonlinearity), shape=shape)\n",
    "    return weight\n",
    "\n",
    "def _conv2d(in_channels, out_channels, kernel_size, stride, pad_mode, padding, group=1, has_bias=False):\n",
    "    '''return conv2d layer with initialized weight'''\n",
    "    if in_channels % group == 0 and out_channels % group == 0:\n",
    "        weight_shape = [out_channels, in_channels//group, kernel_size, kernel_size]\n",
    "    else:\n",
    "        raise ValueError(\"In_ channels:{} and out_channels:{} must be divisible by the number of groups:{}.\"\n",
    "                         .format(in_channels, out_channels, group))\n",
    "    weight = kaiming_normal(weight_shape)\n",
    "    conv = nn.Conv2d(in_channels=in_channels,\n",
    "                     out_channels=out_channels,\n",
    "                     kernel_size=kernel_size,\n",
    "                     stride=stride,\n",
    "                     pad_mode=pad_mode,\n",
    "                     padding=padding,\n",
    "                     group=group,\n",
    "                     has_bias=has_bias,\n",
    "                     weight_init=weight\n",
    "                     )\n",
    "    return conv\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Cell):\n",
    "    '''Convolution layer (conv + bn + relu).'''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            pad_mode='pad',\n",
    "            padding=3,\n",
    "            group=1,\n",
    "            has_bias=False\n",
    "    ):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.conv = _conv2d(in_channels, out_channels, kernel_size,\n",
    "                            stride, pad_mode, padding, group, has_bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1x1(nn.Cell):\n",
    "    \"\"\"1x1 convolution + bn + relu.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, group=1):\n",
    "        super(Conv1x1, self).__init__()\n",
    "        self.conv = _conv2d(in_channels, out_channels, 1, stride=stride, pad_mode='valid', padding=0, group=group)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1x1Linear(nn.Cell):\n",
    "    '''1x1 convolution + bn (w/o non-linearity).'''\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Conv1x1Linear, self).__init__()\n",
    "        self.conv = _conv2d(in_channels, out_channels, 1, stride, pad_mode='valid', padding=0)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv3x3(nn.Cell):\n",
    "    \"\"\"3x3 convolution + bn + relu.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, group=1):\n",
    "        super(Conv3x3, self).__init__()\n",
    "        self.conv = _conv2d(in_channels, out_channels, 3, stride, pad_mode='pad', padding=1, group=group)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LightConv3x3(nn.Cell):\n",
    "    \"\"\"Lightweight 3x3 convolution.\n",
    "    1x1 (linear) + dw 3x3 (nonlinear).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LightConv3x3, self).__init__()\n",
    "        self.conv1 = _conv2d(in_channels, out_channels, 1, stride=1, pad_mode='valid', padding=0)\n",
    "        self.conv2 = _conv2d(out_channels, out_channels, 3, stride=1, pad_mode='pad', padding=1, group=out_channels)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b917e5d",
   "metadata": {},
   "source": [
    "#### ChannelGate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3685f",
   "metadata": {},
   "source": [
    "每个流都可以提供特定尺度的特征，即，它们是尺度均匀的。为了学习全尺度特征，以动态的方式组合不同流的输出，即，不同的权重根据输入图像分配到不同的尺度，而不是经过训练后固定。更具体地说，动态尺度融合是通过一种新的聚合门(AG)实现的，它是一种可学习的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e67e41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelGate(nn.Cell):\n",
    "    \"\"\"A mini-network that generates channel-wise gates conditioned on input tensor.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            num_gates=None,\n",
    "            return_gates=False,\n",
    "            gate_activation='sigmoid',\n",
    "            reduction=16,\n",
    "    ):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        if num_gates is None:\n",
    "            num_gates = in_channels\n",
    "        self.return_gates = return_gates\n",
    "        self.global_avgpool = ops.ReduceMean(keep_dims=True)\n",
    "        self.fc1 = _conv2d(in_channels, in_channels//reduction, kernel_size=1, stride=1,\n",
    "                           pad_mode='valid', padding=0, has_bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = _conv2d(in_channels//reduction, num_gates, kernel_size=1, stride=1,\n",
    "                           pad_mode='valid', padding=0, has_bias=True)\n",
    "        if gate_activation == 'sigmoid':\n",
    "            self.gate_activation = nn.Sigmoid()\n",
    "        elif gate_activation == 'relu':\n",
    "            self.gate_activation = nn.ReLU()\n",
    "        elif gate_activation == 'linear':\n",
    "            self.gate_activation = None\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                \"Unknown gate activation: {}\".format(gate_activation)\n",
    "            )\n",
    "\n",
    "    def construct(self, x):\n",
    "        '''constuct function'''\n",
    "        inputs = x\n",
    "        x = self.global_avgpool(x, (2, 3))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        if self.gate_activation is not None:\n",
    "            x = self.gate_activation(x)\n",
    "        if self.return_gates:\n",
    "            return x\n",
    "        return inputs * x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad20fc",
   "metadata": {},
   "source": [
    "#### OSBlock（bottleneck）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef8d14",
   "metadata": {},
   "source": [
    "![](./img/osblock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768164f",
   "metadata": {},
   "source": [
    "使用全尺度残差块OSBlock（b）代替传统残差块（a）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d77352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSBlock(nn.Cell):\n",
    "    \"\"\"Omni-scale feature learning block.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            bottleneck_reduction=4,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super(OSBlock, self).__init__()\n",
    "        mid_channels = out_channels // bottleneck_reduction\n",
    "        self.conv1 = Conv1x1(in_channels, mid_channels)\n",
    "        self.conv2a = LightConv3x3(mid_channels, mid_channels)\n",
    "        self.conv2b = nn.SequentialCell(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.conv2c = nn.SequentialCell(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.conv2d = nn.SequentialCell(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.gate = ChannelGate(mid_channels)\n",
    "        self.conv3 = Conv1x1Linear(mid_channels, out_channels)\n",
    "        self.downsample = None\n",
    "        self.relu = nn.ReLU()\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = Conv1x1Linear(in_channels, out_channels)\n",
    "\n",
    "    def construct(self, x):\n",
    "        '''construct layer'''\n",
    "        identity = x\n",
    "        x1 = self.conv1(x)\n",
    "        x2a = self.conv2a(x1)\n",
    "        x2b = self.conv2b(x1)\n",
    "        x2c = self.conv2c(x1)\n",
    "        x2d = self.conv2d(x1)\n",
    "        x2 = self.gate(x2a) + self.gate(x2b) + self.gate(x2c) + self.gate(x2d)\n",
    "        x3 = self.conv3(x2)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        add = x3 + identity\n",
    "        out = self.relu(add)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d15e49",
   "metadata": {},
   "source": [
    "#### OSNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0189f",
   "metadata": {},
   "source": [
    "![](./img/Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a326cf",
   "metadata": {},
   "source": [
    "OSNet是通过简单地逐层堆叠轻量级bottleneck构建，上图为网络架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c14ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSNet(nn.Cell):\n",
    "    \"\"\"Omni-Scale Network.\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes,\n",
    "            blocks,\n",
    "            layers,\n",
    "            channels,\n",
    "            feature_dim=512,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super(OSNet, self).__init__()\n",
    "        num_blocks = len(blocks)\n",
    "        assert num_blocks == len(layers)\n",
    "        assert num_blocks == len(channels) - 1\n",
    "        self.feature_dim = feature_dim\n",
    "        self.conv1 = ConvLayer(3, channels[0], 7, stride=2, padding=3)\n",
    "        self.pad = nn.Pad(paddings=((0, 0), (0, 0), (1, 1), (1, 1)), mode=\"CONSTANT\")\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = self._make_layer(\n",
    "            blocks[0],\n",
    "            layers[0],\n",
    "            channels[0],\n",
    "            channels[1],\n",
    "            reduce_spatial_size=True,\n",
    "        )\n",
    "        self.conv3 = self._make_layer(\n",
    "            blocks[1],\n",
    "            layers[1],\n",
    "            channels[1],\n",
    "            channels[2],\n",
    "            reduce_spatial_size=True\n",
    "        )\n",
    "        self.conv4 = self._make_layer(\n",
    "            blocks[2],\n",
    "            layers[2],\n",
    "            channels[2],\n",
    "            channels[3],\n",
    "            reduce_spatial_size=False\n",
    "        )\n",
    "        self.conv5 = Conv1x1(channels[3], channels[3])\n",
    "        self.global_avgpool = ops.ReduceMean(keep_dims=True)\n",
    "        self.fc = self._construct_fc_layer(\n",
    "            self.feature_dim, channels[3], dropout_p=None\n",
    "        )\n",
    "        self.classifier = nn.Dense(self.feature_dim, num_classes)\n",
    "        self.stop_layer = ops.Identity()\n",
    "\n",
    "    def _make_layer(\n",
    "            self,\n",
    "            block,\n",
    "            layer,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            reduce_spatial_size,\n",
    "    ):\n",
    "        '''make block layers.'''\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels))\n",
    "        for _ in range(1, layer):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        if reduce_spatial_size:\n",
    "            layers.append(\n",
    "                nn.SequentialCell(\n",
    "                    Conv1x1(out_channels, out_channels),\n",
    "                    nn.AvgPool2d(2, stride=2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.SequentialCell(*layers)\n",
    "\n",
    "    def _construct_fc_layer(self, fc_dims, input_dim, dropout_p=None):\n",
    "        '''constuct full-connection layer.'''\n",
    "        if fc_dims is None or fc_dims < 0:\n",
    "            self.feature_dim = input_dim\n",
    "            return None\n",
    "        if isinstance(fc_dims, int):\n",
    "            fc_dims = [fc_dims]\n",
    "\n",
    "        layers = []\n",
    "        for dim in fc_dims:\n",
    "            layers.append(nn.Dense(input_dim, dim))\n",
    "            layers.append(nn.BatchNorm1d(dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_p is not None:\n",
    "                layers.append(nn.Dropout(p=dropout_p))\n",
    "            input_dim = dim\n",
    "\n",
    "        self.feature_dim = fc_dims[-1]\n",
    "\n",
    "        return nn.SequentialCell(*layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        '''construct'''\n",
    "        x = self.conv1(x)\n",
    "        x = self.pad(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        v = self.global_avgpool(x, (2, 3))\n",
    "        v = v.view(v.shape[0], -1)\n",
    "        if self.fc is not None:\n",
    "            v = self.fc(v)\n",
    "        if not self.training:\n",
    "            return v\n",
    "        y = self.stop_layer(v)\n",
    "        y = self.classifier(v)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0b0af",
   "metadata": {},
   "source": [
    "## 数据集准备与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0430c9f",
   "metadata": {},
   "source": [
    "### 下载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3a523",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/pengcw1/market-1501/download?datasetVersionNumber=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b3f02",
   "metadata": {},
   "source": [
    "### 数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377c247",
   "metadata": {},
   "source": [
    "Market-1501数据集[1]在清华开放环境通过6个摄像头采集得到，一共包括1501个行人，其中训练集中751个行人12936张图片，测试集（gallery）中750个行人19732张图片，query集中3368张图片。\n",
    "\n",
    "数据文件说明：\n",
    "1.  “bounding_box_test”——用于测试集的 750 人，包含 19,732 张图像，前缀为 0000 表示在提取这 750 人的过程中DPM检测错的图（可能与query是同一个人），-1 表示检测出来其他人的图（不在这 750 人中）\n",
    "2. “bounding_box_train”——用于训练集的 751 人，包含 12,936 张图像\n",
    "3. “query”——为 750 人在每个摄像头中随机选择一张图像作为query，因此一个人的query最多有 6 个，共有 3,368 张图像\n",
    "4. “gt_query”——matlab格式，用于判断一个query的哪些图片是好的匹配（同一个人不同摄像头的图像）和不好的匹配（同一个人同一个摄像头的图像或非同一个人的图像）\n",
    "5. “gt_bbox”——手工标注的bounding box，用于判断DPM检测的bounding box是不是一个好的box\n",
    "\n",
    "文件命名方式：\n",
    "例如：0001_c1s1_001051_01.jpg\n",
    "\n",
    "1. 0001 是行人 ID，Market 1501 有 1501 个行人，故行人 ID 范围为 0001-1501\n",
    "2. c1 是摄像头编号(camera 4)，表明图片采集自第1个摄像头，一共有 6 个摄像头\n",
    "3. s1 是视频的第一个片段(sequece1)，一个视频包含若干个片段\n",
    "4. 001051 是视频的第 1051 帧图片，表明行人出现在该帧图片中\n",
    "5. 01 代表第 826 帧图片上的第一个检测框，DPM 检测器可能在一帧图片上生成多个检测框，00为手工标注"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94e111",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf4ef0",
   "metadata": {},
   "source": [
    "本案例实现选取Market-1501数据集中10个行人数据构建子数据集，在CPU上实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caaae510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Market10():\n",
    "    _junk_pids = [0, -1]\n",
    "    dataset_dir = 'Market-10'\n",
    "    def __init__(self, root='',mode='train', verbose=True, **kwargs):\n",
    "        self.root = osp.abspath(osp.expanduser(root))\n",
    "        self.data_dir = osp.join(self.root, self.dataset_dir)\n",
    "        self.train_dir = osp.join(self.data_dir, 'train')\n",
    "        self.query_dir = osp.join(self.data_dir, 'query')\n",
    "        self.gallery_dir = osp.join(self.data_dir, 'test')\n",
    "        train = self.process_dir(self.train_dir, relabel=True)\n",
    "        query = self.process_dir(self.query_dir, relabel=False)\n",
    "        gallery = self.process_dir(self.gallery_dir, relabel=False)\n",
    "\n",
    "        if len(train[0]) == 3:\n",
    "            train = [(*items, 0) for items in train]\n",
    "        if len(query[0]) == 3:\n",
    "            query = [(*items, 0) for items in query]\n",
    "        if len(gallery[0]) == 3:\n",
    "            gallery = [(*items, 0) for items in gallery]\n",
    "\n",
    "        self.train = train\n",
    "        self.query = query\n",
    "        self.gallery = gallery\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.num_train_pids = self.get_num_pids(self.train)\n",
    "        self.num_train_cams = self.get_num_cams(self.train)\n",
    "        self.num_datasets = self.get_num_datasets(self.train)\n",
    "\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.data = self.train\n",
    "        elif self.mode == 'query':\n",
    "            self.data = self.query\n",
    "        elif self.mode == 'gallery':\n",
    "            self.data = self.gallery\n",
    "\n",
    "        if self.verbose:\n",
    "            self.show_summary()\n",
    "\n",
    "    def process_dir(self, dir_path, relabel=False):\n",
    "        '''get images and labels from directory.'''\n",
    "        img_paths = glob.glob(osp.join(dir_path, '*.jpg'))\n",
    "        pattern = re.compile(r'([-\\d]+)_c(\\d)')\n",
    "\n",
    "        pid_container = set()\n",
    "        for img_path in img_paths:\n",
    "            pid, _ = map(int, pattern.search(img_path).groups())\n",
    "            if pid == -1:\n",
    "                continue # junk images are just ignored\n",
    "            pid_container.add(pid)\n",
    "        pid2label = {pid: label for label, pid in enumerate(pid_container)}\n",
    "\n",
    "        data = []\n",
    "        for img_path in img_paths:\n",
    "            pid, camid = map(int, pattern.search(img_path).groups())\n",
    "            if pid == -1:\n",
    "                continue # junk images are just ignored\n",
    "            assert 0 <= pid <= 1501 # pid == 0 means background\n",
    "            assert 1 <= camid <= 6\n",
    "            camid -= 1 # index starts from 0\n",
    "            if relabel:\n",
    "                pid = pid2label[pid]\n",
    "            data.append((img_path, pid, camid))\n",
    "\n",
    "        return data\n",
    "    def __getitem__(self, index):\n",
    "        img_path, pid, camid, _ = self.data[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        pid = np.array(pid).astype(np.int32)\n",
    "        if self.mode == 'train':\n",
    "            return img, pid\n",
    "\n",
    "        return img, pid, camid\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_num_pids(self, data):\n",
    "        pids = set()\n",
    "        for items in data:\n",
    "            pid = items[1]\n",
    "            pids.add(pid)\n",
    "        return len(pids)\n",
    "\n",
    "    def get_num_cams(self, data):\n",
    "        cams = set()\n",
    "        for items in data:\n",
    "            camid = items[2]\n",
    "            cams.add(camid)\n",
    "        return len(cams)\n",
    "\n",
    "    def get_num_datasets(self, data):\n",
    "        dsets = set()\n",
    "        for items in data:\n",
    "            dsetid = items[3]\n",
    "            dsets.add(dsetid)\n",
    "        return len(dsets)\n",
    "\n",
    "    def show_summary(self):\n",
    "        num_train_pids = self.get_num_pids(self.train)\n",
    "        num_train_cams = self.get_num_cams(self.train)\n",
    "\n",
    "        num_query_pids = self.get_num_pids(self.query)\n",
    "        num_query_cams = self.get_num_cams(self.query)\n",
    "\n",
    "        num_gallery_pids = self.get_num_pids(self.gallery)\n",
    "        num_gallery_cams = self.get_num_cams(self.gallery)\n",
    "\n",
    "        print('=> Loaded {}'.format(self.__class__.__name__))\n",
    "        print('  ----------------------------------------')\n",
    "        print('  subset   | # ids | # images | # cameras')\n",
    "        print('  ----------------------------------------')\n",
    "        print(\n",
    "            '  train    | {:5d} | {:8d} | {:9d}'.format(\n",
    "                num_train_pids, len(self.train), num_train_cams\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            '  query    | {:5d} | {:8d} | {:9d}'.format(\n",
    "                num_query_pids, len(self.query), num_query_cams\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            '  gallery  | {:5d} | {:8d} | {:9d}'.format(\n",
    "                num_gallery_pids, len(self.gallery), num_gallery_cams\n",
    "            )\n",
    "        )\n",
    "        print('  ----------------------------------------')\n",
    "\n",
    "    def __repr__(self):\n",
    "        num_train_pids = self.get_num_pids(self.train)\n",
    "        num_train_cams = self.get_num_cams(self.train)\n",
    "\n",
    "        num_query_pids = self.get_num_pids(self.query)\n",
    "        num_query_cams = self.get_num_cams(self.query)\n",
    "\n",
    "        num_gallery_pids = self.get_num_pids(self.gallery)\n",
    "        num_gallery_cams = self.get_num_cams(self.gallery)\n",
    "\n",
    "        msg = '  ----------------------------------------\\n' \\\n",
    "              '  subset   | # ids | # items | # cameras\\n' \\\n",
    "              '  ----------------------------------------\\n' \\\n",
    "              '  train    | {:5d} | {:7d} | {:9d}\\n' \\\n",
    "              '  query    | {:5d} | {:7d} | {:9d}\\n' \\\n",
    "              '  gallery  | {:5d} | {:7d} | {:9d}\\n' \\\n",
    "              '  ----------------------------------------\\n' \\\n",
    "              '  items: images/tracklets for image/video dataset\\n'.format(\n",
    "                  num_train_pids, len(self.train), num_train_cams,\n",
    "                  num_query_pids, len(self.query), num_query_cams,\n",
    "                  num_gallery_pids, len(self.gallery), num_gallery_cams\n",
    "              )\n",
    "\n",
    "        return msg\n",
    "\n",
    "\n",
    "def dataset_creator(\n",
    "        root='',\n",
    "        height=256,\n",
    "        width=128,\n",
    "        norm_mean=[0.485, 0.456, 0.406],\n",
    "        norm_std=[0.229, 0.224, 0.225],\n",
    "        batch_size_train=32,\n",
    "        batch_size_test=32,\n",
    "        mode=None\n",
    "):\n",
    "    dataset_ = Market10(root=root, mode=mode)\n",
    "    num_pids = dataset_.num_train_pids\n",
    "\n",
    "    if mode == 'train':\n",
    "        sampler = ds.RandomSampler()\n",
    "        data_set = ds.GeneratorDataset(dataset_, ['img', 'pid'], sampler=sampler)\n",
    "        transforms = Compose([\n",
    "            Resize((height, width)),\n",
    "            RandomHorizontalFlip(),\n",
    "            Rescale(1.0 / 255.0, 0.0),\n",
    "            Normalize(mean=norm_mean, std=norm_std),\n",
    "            HWC2CHW(),\n",
    "        ])\n",
    "        data_set = data_set.map(operations=transforms, input_columns=['img'])\n",
    "        data_set = data_set.batch(batch_size=batch_size_train, drop_remainder=True)\n",
    "        return num_pids, data_set\n",
    "\n",
    "    data_set = ds.GeneratorDataset(dataset_, ['img', 'pid', 'camid'])\n",
    "    transforms = Compose([\n",
    "        Resize((height, width)),\n",
    "        Rescale(1.0/255.0, 0.0),\n",
    "        Normalize(mean=norm_mean, std=norm_std),\n",
    "        HWC2CHW(),\n",
    "    ])\n",
    "    data_set = data_set.map(operations=transforms, input_columns=['img'])\n",
    "    data_set = data_set.batch(batch_size=batch_size_test, drop_remainder=False)\n",
    "    return num_pids, data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3d61a",
   "metadata": {},
   "source": [
    "## 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78fbb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_pretrained_weights(model, pretrained_param_dir):\n",
    "    \"\"\"\n",
    "    Initializes model with pretrained weights.\n",
    "    Layers that don't match with pretrained layers in name or size are kept unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = 'init_osnet.ckpt'\n",
    "    file = os.path.join(pretrained_param_dir, filename)\n",
    "    print(file)\n",
    "    if not os.path.exists(file):\n",
    "        raise ValueError(\n",
    "            'The file:{} does not exist.'.format(file)\n",
    "        )\n",
    "    param_dict = load_checkpoint(file)\n",
    "    model_dict = model.parameters_dict()\n",
    "    new_state_dict = OrderedDict()\n",
    "    matched_layers, discarded_layers = [], []\n",
    "    for k, v in param_dict.items():\n",
    "        if k in model_dict and model_dict[k].data.shape == v.shape:\n",
    "            new_state_dict[k] = v\n",
    "            matched_layers.append(k)\n",
    "        else:\n",
    "            discarded_layers.append(k)\n",
    "\n",
    "    model_dict.update(new_state_dict)\n",
    "    load_param_into_net(model, model_dict)\n",
    "\n",
    "    if not matched_layers:\n",
    "        warnings.warn(\n",
    "            'The pretrained weights from \"{}\" cannot be loaded, '\n",
    "            'please check the key names manually '\n",
    "            '(** ignored and continue **)'.format(file)\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            'Successfully loaded imagenet pretrained weights from \"{}\"'.\n",
    "            format(file)\n",
    "        )\n",
    "        if discarded_layers:\n",
    "            print(\n",
    "                '** The following layers are discarded '\n",
    "                'due to unmatched keys or layer size: {}'.\n",
    "                format(discarded_layers)\n",
    "            )\n",
    "\n",
    "\n",
    "def create_osnet(num_classes=1500, pretrained=False, pretrained_dir='', **kwargs):\n",
    "    '''create osnet.'''\n",
    "    model = OSNet(\n",
    "        num_classes,\n",
    "        blocks=[OSBlock, OSBlock, OSBlock],\n",
    "        layers=[2, 2, 2],\n",
    "        channels=[64, 256, 384, 512],\n",
    "        **kwargs\n",
    "    )\n",
    "    if pretrained:\n",
    "        init_pretrained_weights(model, pretrained_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e469c1",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be6791",
   "metadata": {},
   "source": [
    "模型训练时前10个epoch固定网络参数训练分类器，之后才开始训练网络参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b06c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(19256:16812,MainProcess):2022-09-27-16:54:05.232.537 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n",
      "[WARNING] ME(19256:16812,MainProcess):2022-09-27-16:54:05.238.409 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded Market10\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     5 |       85 |         6\n",
      "  query    |     5 |       24 |         6\n",
      "  gallery  |     5 |       89 |         6\n",
      "  ----------------------------------------\n",
      "=> Loaded Market10\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     5 |       85 |         6\n",
      "  query    |     5 |       24 |         6\n",
      "  gallery  |     5 |       89 |         6\n",
      "  ----------------------------------------\n",
      "./pretrained_model\\init_osnet.ckpt\n",
      "Successfully loaded imagenet pretrained weights from \"./pretrained_model\\init_osnet.ckpt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Epoch:[  0/ 10], step:[    1/    2], loss:[1.656/1.656], time:5912.812 ms, lr:0.00100\n",
      "Epoch:[  0/ 10], step:[    2/    2], loss:[1.535/1.595], time:1469.615 ms, lr:0.00100\n",
      "Train epoch time: 7414.327 ms, per step time: 3707.163 ms\n",
      "Epoch time: 7415.327 ms, per step time: 3707.663 ms, avg loss: 1.595\n",
      "Epoch:[  1/ 10], step:[    1/    2], loss:[1.444/1.444], time:1467.467 ms, lr:0.00100\n",
      "Epoch:[  1/ 10], step:[    2/    2], loss:[1.348/1.396], time:1410.258 ms, lr:0.00100\n",
      "Train epoch time: 2893.740 ms, per step time: 1446.870 ms\n",
      "Epoch time: 2893.740 ms, per step time: 1446.870 ms, avg loss: 1.396\n",
      "Epoch:[  2/ 10], step:[    1/    2], loss:[1.288/1.288], time:1433.255 ms, lr:0.00100\n",
      "Epoch:[  2/ 10], step:[    2/    2], loss:[1.371/1.330], time:1078.606 ms, lr:0.00100\n",
      "Train epoch time: 2525.873 ms, per step time: 1262.937 ms\n",
      "Epoch time: 2525.873 ms, per step time: 1262.937 ms, avg loss: 1.330\n",
      "Epoch:[  3/ 10], step:[    1/    2], loss:[1.307/1.307], time:1299.649 ms, lr:0.00100\n",
      "Epoch:[  3/ 10], step:[    2/    2], loss:[1.222/1.265], time:1153.976 ms, lr:0.00100\n",
      "Train epoch time: 2467.635 ms, per step time: 1233.818 ms\n",
      "Epoch time: 2467.635 ms, per step time: 1233.818 ms, avg loss: 1.265\n",
      "Epoch:[  4/ 10], step:[    1/    2], loss:[1.190/1.190], time:1138.340 ms, lr:0.00100\n",
      "Epoch:[  4/ 10], step:[    2/    2], loss:[1.052/1.121], time:1031.878 ms, lr:0.00100\n",
      "Train epoch time: 2183.228 ms, per step time: 1091.614 ms\n",
      "Epoch time: 2183.228 ms, per step time: 1091.614 ms, avg loss: 1.121\n",
      "Epoch:[  5/ 10], step:[    1/    2], loss:[1.120/1.120], time:977.526 ms, lr:0.00100\n",
      "Epoch:[  5/ 10], step:[    2/    2], loss:[1.062/1.091], time:912.907 ms, lr:0.00100\n",
      "Train epoch time: 1904.446 ms, per step time: 952.223 ms\n",
      "Epoch time: 1905.447 ms, per step time: 952.724 ms, avg loss: 1.091\n",
      "Epoch:[  6/ 10], step:[    1/    2], loss:[0.984/0.984], time:1126.832 ms, lr:0.00100\n",
      "Epoch:[  6/ 10], step:[    2/    2], loss:[1.045/1.014], time:1119.888 ms, lr:0.00100\n",
      "Train epoch time: 2261.734 ms, per step time: 1130.867 ms\n",
      "Epoch time: 2262.735 ms, per step time: 1131.367 ms, avg loss: 1.014\n",
      "Epoch:[  7/ 10], step:[    1/    2], loss:[1.015/1.015], time:1010.920 ms, lr:0.00100\n",
      "Epoch:[  7/ 10], step:[    2/    2], loss:[0.913/0.964], time:863.622 ms, lr:0.00100\n",
      "Train epoch time: 1890.557 ms, per step time: 945.279 ms\n",
      "Epoch time: 1890.557 ms, per step time: 945.279 ms, avg loss: 0.964\n",
      "Epoch:[  8/ 10], step:[    1/    2], loss:[0.911/0.911], time:829.319 ms, lr:0.00100\n",
      "Epoch:[  8/ 10], step:[    2/    2], loss:[0.959/0.935], time:1297.427 ms, lr:0.00100\n",
      "Train epoch time: 2140.760 ms, per step time: 1070.380 ms\n",
      "Epoch time: 2141.761 ms, per step time: 1070.880 ms, avg loss: 0.935\n",
      "Epoch:[  9/ 10], step:[    1/    2], loss:[0.828/0.828], time:1228.424 ms, lr:0.00100\n",
      "Epoch:[  9/ 10], step:[    2/    2], loss:[0.867/0.848], time:1338.415 ms, lr:0.00100\n",
      "Train epoch time: 2581.362 ms, per step time: 1290.681 ms\n",
      "Epoch time: 2582.352 ms, per step time: 1291.176 ms, avg loss: 0.848\n",
      "Epoch:[  0/240], step:[    1/    2], loss:[0.837/0.837], time:12160.203 ms, lr:0.00100\n",
      "Epoch:[  0/240], step:[    2/    2], loss:[0.820/0.828], time:4072.500 ms, lr:0.00100\n",
      "Train epoch time: 16323.324 ms, per step time: 8161.662 ms\n",
      "Epoch time: 16324.325 ms, per step time: 8162.163 ms, avg loss: 0.828\n",
      "Epoch:[  1/240], step:[    1/    2], loss:[0.581/0.581], time:3996.188 ms, lr:0.00100\n",
      "Epoch:[  1/240], step:[    2/    2], loss:[0.547/0.564], time:3875.312 ms, lr:0.00100\n",
      "Train epoch time: 7892.521 ms, per step time: 3946.260 ms\n",
      "Epoch time: 7893.521 ms, per step time: 3946.761 ms, avg loss: 0.564\n",
      "Epoch:[  2/240], step:[    1/    2], loss:[0.546/0.546], time:4050.331 ms, lr:0.00099\n",
      "Epoch:[  2/240], step:[    2/    2], loss:[0.511/0.528], time:3073.468 ms, lr:0.00099\n",
      "Train epoch time: 7144.817 ms, per step time: 3572.409 ms\n",
      "Epoch time: 7145.818 ms, per step time: 3572.909 ms, avg loss: 0.528\n",
      "Epoch:[  3/240], step:[    1/    2], loss:[0.505/0.505], time:3153.737 ms, lr:0.00099\n",
      "Epoch:[  3/240], step:[    2/    2], loss:[0.506/0.506], time:3217.802 ms, lr:0.00099\n",
      "Train epoch time: 6391.558 ms, per step time: 3195.779 ms\n",
      "Epoch time: 6392.558 ms, per step time: 3196.279 ms, avg loss: 0.506\n",
      "Epoch:[  4/240], step:[    1/    2], loss:[0.507/0.507], time:3166.186 ms, lr:0.00099\n",
      "Epoch:[  4/240], step:[    2/    2], loss:[0.512/0.510], time:3205.839 ms, lr:0.00099\n",
      "Train epoch time: 6393.043 ms, per step time: 3196.522 ms\n",
      "Epoch time: 6394.044 ms, per step time: 3197.022 ms, avg loss: 0.510\n",
      "Epoch:[  5/240], step:[    1/    2], loss:[0.500/0.500], time:3116.031 ms, lr:0.00099\n",
      "Epoch:[  5/240], step:[    2/    2], loss:[0.498/0.499], time:3063.529 ms, lr:0.00099\n",
      "Train epoch time: 6202.573 ms, per step time: 3101.287 ms\n",
      "Epoch time: 6203.574 ms, per step time: 3101.787 ms, avg loss: 0.499\n",
      "Epoch:[  6/240], step:[    1/    2], loss:[0.492/0.492], time:3244.676 ms, lr:0.00099\n",
      "Epoch:[  6/240], step:[    2/    2], loss:[0.484/0.488], time:3236.056 ms, lr:0.00099\n",
      "Train epoch time: 6502.765 ms, per step time: 3251.382 ms\n",
      "Epoch time: 6503.766 ms, per step time: 3251.883 ms, avg loss: 0.488\n",
      "Epoch:[  7/240], step:[    1/    2], loss:[0.492/0.492], time:2971.874 ms, lr:0.00099\n",
      "Epoch:[  7/240], step:[    2/    2], loss:[0.494/0.493], time:2599.693 ms, lr:0.00099\n",
      "Train epoch time: 5594.585 ms, per step time: 2797.292 ms\n",
      "Epoch time: 5595.586 ms, per step time: 2797.793 ms, avg loss: 0.493\n",
      "Epoch:[  8/240], step:[    1/    2], loss:[0.487/0.487], time:2665.281 ms, lr:0.00099\n",
      "Epoch:[  8/240], step:[    2/    2], loss:[0.528/0.508], time:2797.141 ms, lr:0.00099\n",
      "Train epoch time: 5481.438 ms, per step time: 2740.719 ms\n",
      "Epoch time: 5483.440 ms, per step time: 2741.720 ms, avg loss: 0.508\n",
      "Epoch:[  9/240], step:[    1/    2], loss:[0.479/0.479], time:2878.395 ms, lr:0.00099\n",
      "Epoch:[  9/240], step:[    2/    2], loss:[0.490/0.485], time:2899.641 ms, lr:0.00099\n",
      "Train epoch time: 5984.459 ms, per step time: 2992.230 ms\n",
      "Epoch time: 5985.460 ms, per step time: 2992.730 ms, avg loss: 0.485\n",
      "Epoch:[ 10/240], step:[    1/    2], loss:[0.490/0.490], time:2888.857 ms, lr:0.00098\n",
      "Epoch:[ 10/240], step:[    2/    2], loss:[0.478/0.484], time:2690.509 ms, lr:0.00098\n",
      "Train epoch time: 5600.385 ms, per step time: 2800.192 ms\n",
      "Epoch time: 5601.386 ms, per step time: 2800.693 ms, avg loss: 0.484\n",
      "Epoch:[ 11/240], step:[    1/    2], loss:[0.487/0.487], time:2920.438 ms, lr:0.00098\n",
      "Epoch:[ 11/240], step:[    2/    2], loss:[0.482/0.484], time:2945.482 ms, lr:0.00098\n",
      "Train epoch time: 5887.938 ms, per step time: 2943.969 ms\n",
      "Epoch time: 5888.938 ms, per step time: 2944.469 ms, avg loss: 0.484\n",
      "Epoch:[ 12/240], step:[    1/    2], loss:[0.510/0.510], time:2634.609 ms, lr:0.00098\n",
      "Epoch:[ 12/240], step:[    2/    2], loss:[0.479/0.495], time:2737.700 ms, lr:0.00098\n",
      "Train epoch time: 5393.327 ms, per step time: 2696.664 ms\n",
      "Epoch time: 5394.328 ms, per step time: 2697.164 ms, avg loss: 0.495\n",
      "Epoch:[ 13/240], step:[    1/    2], loss:[0.491/0.491], time:2702.793 ms, lr:0.00098\n",
      "Epoch:[ 13/240], step:[    2/    2], loss:[0.488/0.490], time:2838.856 ms, lr:0.00098\n",
      "Train epoch time: 5560.666 ms, per step time: 2780.333 ms\n",
      "Epoch time: 5561.666 ms, per step time: 2780.833 ms, avg loss: 0.490\n",
      "Epoch:[ 14/240], step:[    1/    2], loss:[0.485/0.485], time:2984.458 ms, lr:0.00098\n",
      "Epoch:[ 14/240], step:[    2/    2], loss:[0.477/0.481], time:2718.945 ms, lr:0.00098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch time: 5723.422 ms, per step time: 2861.711 ms\n",
      "Epoch time: 5724.423 ms, per step time: 2862.211 ms, avg loss: 0.481\n",
      "Epoch:[ 15/240], step:[    1/    2], loss:[0.483/0.483], time:2664.919 ms, lr:0.00098\n",
      "Epoch:[ 15/240], step:[    2/    2], loss:[0.474/0.479], time:2549.893 ms, lr:0.00098\n",
      "Train epoch time: 5235.832 ms, per step time: 2617.916 ms\n",
      "Epoch time: 5236.833 ms, per step time: 2618.417 ms, avg loss: 0.479\n",
      "Epoch:[ 16/240], step:[    1/    2], loss:[0.477/0.477], time:2504.364 ms, lr:0.00097\n",
      "Epoch:[ 16/240], step:[    2/    2], loss:[0.477/0.477], time:2661.165 ms, lr:0.00097\n",
      "Train epoch time: 5187.548 ms, per step time: 2593.774 ms\n",
      "Epoch time: 5188.549 ms, per step time: 2594.275 ms, avg loss: 0.477\n",
      "Epoch:[ 17/240], step:[    1/    2], loss:[0.475/0.475], time:2718.243 ms, lr:0.00097\n",
      "Epoch:[ 17/240], step:[    2/    2], loss:[0.475/0.475], time:2767.173 ms, lr:0.00097\n",
      "Train epoch time: 5504.433 ms, per step time: 2752.216 ms\n",
      "Epoch time: 5505.434 ms, per step time: 2752.717 ms, avg loss: 0.475\n",
      "Epoch:[ 18/240], step:[    1/    2], loss:[0.476/0.476], time:2673.013 ms, lr:0.00097\n",
      "Epoch:[ 18/240], step:[    2/    2], loss:[0.471/0.474], time:2579.517 ms, lr:0.00097\n",
      "Train epoch time: 5274.546 ms, per step time: 2637.273 ms\n",
      "Epoch time: 5275.547 ms, per step time: 2637.773 ms, avg loss: 0.474\n",
      "Epoch:[ 19/240], step:[    1/    2], loss:[0.478/0.478], time:2726.948 ms, lr:0.00097\n",
      "Epoch:[ 19/240], step:[    2/    2], loss:[0.475/0.476], time:2773.045 ms, lr:0.00097\n",
      "Train epoch time: 5763.343 ms, per step time: 2881.672 ms\n",
      "Epoch time: 5764.344 ms, per step time: 2882.172 ms, avg loss: 0.476\n",
      "Epoch:[ 20/240], step:[    1/    2], loss:[0.484/0.484], time:2781.720 ms, lr:0.00096\n",
      "Epoch:[ 20/240], step:[    2/    2], loss:[0.477/0.481], time:2700.055 ms, lr:0.00096\n",
      "Train epoch time: 5501.793 ms, per step time: 2750.897 ms\n",
      "Epoch time: 5502.794 ms, per step time: 2751.397 ms, avg loss: 0.481\n",
      "Epoch:[ 21/240], step:[    1/    2], loss:[0.483/0.483], time:2666.413 ms, lr:0.00096\n",
      "Epoch:[ 21/240], step:[    2/    2], loss:[0.490/0.487], time:2716.386 ms, lr:0.00096\n",
      "Train epoch time: 5402.885 ms, per step time: 2701.443 ms\n",
      "Epoch time: 5403.887 ms, per step time: 2701.943 ms, avg loss: 0.487\n",
      "Epoch:[ 22/240], step:[    1/    2], loss:[0.472/0.472], time:2600.930 ms, lr:0.00096\n",
      "Epoch:[ 22/240], step:[    2/    2], loss:[0.478/0.475], time:2887.270 ms, lr:0.00096\n",
      "Train epoch time: 5507.213 ms, per step time: 2753.607 ms\n",
      "Epoch time: 5508.214 ms, per step time: 2754.107 ms, avg loss: 0.475\n",
      "Epoch:[ 23/240], step:[    1/    2], loss:[0.472/0.472], time:2605.463 ms, lr:0.00096\n",
      "Epoch:[ 23/240], step:[    2/    2], loss:[0.476/0.474], time:2562.039 ms, lr:0.00096\n",
      "Train epoch time: 5189.520 ms, per step time: 2594.760 ms\n",
      "Epoch time: 5190.521 ms, per step time: 2595.261 ms, avg loss: 0.474\n",
      "Epoch:[ 24/240], step:[    1/    2], loss:[0.474/0.474], time:2668.921 ms, lr:0.00096\n",
      "Epoch:[ 24/240], step:[    2/    2], loss:[0.470/0.472], time:2706.557 ms, lr:0.00096\n",
      "Train epoch time: 5395.497 ms, per step time: 2697.749 ms\n",
      "Epoch time: 5396.498 ms, per step time: 2698.249 ms, avg loss: 0.472\n",
      "Epoch:[ 25/240], step:[    1/    2], loss:[0.471/0.471], time:2650.365 ms, lr:0.00095\n",
      "Epoch:[ 25/240], step:[    2/    2], loss:[0.472/0.471], time:2522.393 ms, lr:0.00095\n",
      "Train epoch time: 5191.775 ms, per step time: 2595.887 ms\n",
      "Epoch time: 5192.776 ms, per step time: 2596.388 ms, avg loss: 0.471\n",
      "Epoch:[ 26/240], step:[    1/    2], loss:[0.479/0.479], time:2503.570 ms, lr:0.00095\n",
      "Epoch:[ 26/240], step:[    2/    2], loss:[0.475/0.477], time:2525.949 ms, lr:0.00095\n",
      "Train epoch time: 5050.538 ms, per step time: 2525.269 ms\n",
      "Epoch time: 5051.539 ms, per step time: 2525.770 ms, avg loss: 0.477\n",
      "Epoch:[ 27/240], step:[    1/    2], loss:[0.481/0.481], time:2513.163 ms, lr:0.00095\n",
      "Epoch:[ 27/240], step:[    2/    2], loss:[0.469/0.475], time:2502.630 ms, lr:0.00095\n",
      "Train epoch time: 5035.801 ms, per step time: 2517.901 ms\n",
      "Epoch time: 5036.802 ms, per step time: 2518.401 ms, avg loss: 0.475\n",
      "Epoch:[ 28/240], step:[    1/    2], loss:[0.477/0.477], time:2577.014 ms, lr:0.00094\n",
      "Epoch:[ 28/240], step:[    2/    2], loss:[0.477/0.477], time:2504.764 ms, lr:0.00094\n",
      "Train epoch time: 5099.794 ms, per step time: 2549.897 ms\n",
      "Epoch time: 5100.795 ms, per step time: 2550.398 ms, avg loss: 0.477\n",
      "Epoch:[ 29/240], step:[    1/    2], loss:[0.473/0.473], time:2483.919 ms, lr:0.00094\n",
      "Epoch:[ 29/240], step:[    2/    2], loss:[0.482/0.477], time:2492.494 ms, lr:0.00094\n",
      "Train epoch time: 5248.010 ms, per step time: 2624.005 ms\n",
      "Epoch time: 5249.022 ms, per step time: 2624.511 ms, avg loss: 0.477\n",
      "Epoch:[ 30/240], step:[    1/    2], loss:[0.472/0.472], time:2706.544 ms, lr:0.00094\n",
      "Epoch:[ 30/240], step:[    2/    2], loss:[0.470/0.471], time:2743.342 ms, lr:0.00094\n",
      "Train epoch time: 5471.904 ms, per step time: 2735.952 ms\n",
      "Epoch time: 5472.904 ms, per step time: 2736.452 ms, avg loss: 0.471\n",
      "Epoch:[ 31/240], step:[    1/    2], loss:[0.479/0.479], time:2764.003 ms, lr:0.00094\n",
      "Epoch:[ 31/240], step:[    2/    2], loss:[0.469/0.474], time:3084.045 ms, lr:0.00094\n",
      "Train epoch time: 5873.071 ms, per step time: 2936.536 ms\n",
      "Epoch time: 5874.072 ms, per step time: 2937.036 ms, avg loss: 0.474\n",
      "Epoch:[ 32/240], step:[    1/    2], loss:[0.473/0.473], time:2705.803 ms, lr:0.00093\n",
      "Epoch:[ 32/240], step:[    2/    2], loss:[0.483/0.478], time:2699.165 ms, lr:0.00093\n",
      "Train epoch time: 5426.940 ms, per step time: 2713.470 ms\n",
      "Epoch time: 5426.940 ms, per step time: 2713.470 ms, avg loss: 0.478\n",
      "Epoch:[ 33/240], step:[    1/    2], loss:[0.477/0.477], time:2721.763 ms, lr:0.00093\n",
      "Epoch:[ 33/240], step:[    2/    2], loss:[0.481/0.479], time:3065.639 ms, lr:0.00093\n",
      "Train epoch time: 5807.420 ms, per step time: 2903.710 ms\n",
      "Epoch time: 5808.421 ms, per step time: 2904.211 ms, avg loss: 0.479\n",
      "Epoch:[ 34/240], step:[    1/    2], loss:[0.472/0.472], time:2887.421 ms, lr:0.00093\n",
      "Epoch:[ 34/240], step:[    2/    2], loss:[0.468/0.470], time:3374.775 ms, lr:0.00093\n",
      "Train epoch time: 6284.216 ms, per step time: 3142.108 ms\n",
      "Epoch time: 6285.217 ms, per step time: 3142.608 ms, avg loss: 0.470\n",
      "Epoch:[ 35/240], step:[    1/    2], loss:[0.470/0.470], time:2623.154 ms, lr:0.00092\n",
      "Epoch:[ 35/240], step:[    2/    2], loss:[0.469/0.470], time:2651.751 ms, lr:0.00092\n",
      "Train epoch time: 5296.912 ms, per step time: 2648.456 ms\n",
      "Epoch time: 5297.913 ms, per step time: 2648.956 ms, avg loss: 0.470\n",
      "Epoch:[ 36/240], step:[    1/    2], loss:[0.469/0.469], time:2608.609 ms, lr:0.00092\n",
      "Epoch:[ 36/240], step:[    2/    2], loss:[0.481/0.475], time:2609.444 ms, lr:0.00092\n",
      "Train epoch time: 5238.072 ms, per step time: 2619.036 ms\n",
      "Epoch time: 5239.072 ms, per step time: 2619.536 ms, avg loss: 0.475\n",
      "Epoch:[ 37/240], step:[    1/    2], loss:[0.467/0.467], time:2584.133 ms, lr:0.00092\n",
      "Epoch:[ 37/240], step:[    2/    2], loss:[0.468/0.468], time:2751.788 ms, lr:0.00092\n",
      "Train epoch time: 5356.940 ms, per step time: 2678.470 ms\n",
      "Epoch time: 5357.941 ms, per step time: 2678.970 ms, avg loss: 0.468\n",
      "Epoch:[ 38/240], step:[    1/    2], loss:[0.468/0.468], time:2760.672 ms, lr:0.00091\n",
      "Epoch:[ 38/240], step:[    2/    2], loss:[0.469/0.469], time:2578.940 ms, lr:0.00091\n",
      "Train epoch time: 5359.625 ms, per step time: 2679.813 ms\n",
      "Epoch time: 5360.626 ms, per step time: 2680.313 ms, avg loss: 0.469\n",
      "Epoch:[ 39/240], step:[    1/    2], loss:[0.467/0.467], time:2589.228 ms, lr:0.00091\n",
      "Epoch:[ 39/240], step:[    2/    2], loss:[0.477/0.472], time:2539.859 ms, lr:0.00091\n",
      "Train epoch time: 5409.482 ms, per step time: 2704.741 ms\n",
      "Epoch time: 5410.483 ms, per step time: 2705.242 ms, avg loss: 0.472\n",
      "Epoch:[ 40/240], step:[    1/    2], loss:[0.471/0.471], time:2605.411 ms, lr:0.00090\n",
      "Epoch:[ 40/240], step:[    2/    2], loss:[0.467/0.469], time:2630.193 ms, lr:0.00090\n",
      "Train epoch time: 5257.270 ms, per step time: 2628.635 ms\n",
      "Epoch time: 5258.271 ms, per step time: 2629.135 ms, avg loss: 0.469\n",
      "Epoch:[ 41/240], step:[    1/    2], loss:[0.469/0.469], time:2761.307 ms, lr:0.00090\n",
      "Epoch:[ 41/240], step:[    2/    2], loss:[0.469/0.469], time:2618.747 ms, lr:0.00090\n",
      "Train epoch time: 5401.070 ms, per step time: 2700.535 ms\n",
      "Epoch time: 5402.071 ms, per step time: 2701.036 ms, avg loss: 0.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 42/240], step:[    1/    2], loss:[0.474/0.474], time:3039.341 ms, lr:0.00090\n",
      "Epoch:[ 42/240], step:[    2/    2], loss:[0.470/0.472], time:2992.615 ms, lr:0.00090\n",
      "Train epoch time: 6051.972 ms, per step time: 3025.986 ms\n",
      "Epoch time: 6052.973 ms, per step time: 3026.487 ms, avg loss: 0.472\n",
      "Epoch:[ 43/240], step:[    1/    2], loss:[0.481/0.481], time:2619.278 ms, lr:0.00089\n",
      "Epoch:[ 43/240], step:[    2/    2], loss:[0.470/0.475], time:2749.896 ms, lr:0.00089\n",
      "Train epoch time: 5390.192 ms, per step time: 2695.096 ms\n",
      "Epoch time: 5391.193 ms, per step time: 2695.596 ms, avg loss: 0.475\n",
      "Epoch:[ 44/240], step:[    1/    2], loss:[0.468/0.468], time:2880.180 ms, lr:0.00089\n",
      "Epoch:[ 44/240], step:[    2/    2], loss:[0.467/0.467], time:2792.932 ms, lr:0.00089\n",
      "Train epoch time: 5694.185 ms, per step time: 2847.093 ms\n",
      "Epoch time: 5694.185 ms, per step time: 2847.093 ms, avg loss: 0.467\n",
      "Epoch:[ 45/240], step:[    1/    2], loss:[0.468/0.468], time:2791.085 ms, lr:0.00089\n",
      "Epoch:[ 45/240], step:[    2/    2], loss:[0.468/0.468], time:2641.570 ms, lr:0.00089\n",
      "Train epoch time: 5453.658 ms, per step time: 2726.829 ms\n",
      "Epoch time: 5454.659 ms, per step time: 2727.330 ms, avg loss: 0.468\n",
      "Epoch:[ 46/240], step:[    1/    2], loss:[0.467/0.467], time:2747.627 ms, lr:0.00088\n",
      "Epoch:[ 46/240], step:[    2/    2], loss:[0.470/0.468], time:2638.777 ms, lr:0.00088\n",
      "Train epoch time: 5405.420 ms, per step time: 2702.710 ms\n",
      "Epoch time: 5406.421 ms, per step time: 2703.211 ms, avg loss: 0.468\n",
      "Epoch:[ 47/240], step:[    1/    2], loss:[0.478/0.478], time:2908.390 ms, lr:0.00088\n",
      "Epoch:[ 47/240], step:[    2/    2], loss:[0.494/0.486], time:2782.621 ms, lr:0.00088\n",
      "Train epoch time: 5713.044 ms, per step time: 2856.522 ms\n",
      "Epoch time: 5714.045 ms, per step time: 2857.022 ms, avg loss: 0.486\n",
      "Epoch:[ 48/240], step:[    1/    2], loss:[0.474/0.474], time:2878.938 ms, lr:0.00087\n",
      "Epoch:[ 48/240], step:[    2/    2], loss:[0.471/0.472], time:2689.661 ms, lr:0.00087\n",
      "Train epoch time: 5588.616 ms, per step time: 2794.308 ms\n",
      "Epoch time: 5589.617 ms, per step time: 2794.809 ms, avg loss: 0.472\n",
      "Epoch:[ 49/240], step:[    1/    2], loss:[0.468/0.468], time:2996.171 ms, lr:0.00087\n",
      "Epoch:[ 49/240], step:[    2/    2], loss:[0.473/0.471], time:3020.334 ms, lr:0.00087\n",
      "Train epoch time: 6283.949 ms, per step time: 3141.975 ms\n",
      "Epoch time: 6285.352 ms, per step time: 3142.676 ms, avg loss: 0.471\n",
      "Epoch:[ 50/240], step:[    1/    2], loss:[0.473/0.473], time:2758.217 ms, lr:0.00086\n",
      "Epoch:[ 50/240], step:[    2/    2], loss:[0.474/0.473], time:3539.496 ms, lr:0.00086\n",
      "Train epoch time: 6320.724 ms, per step time: 3160.362 ms\n",
      "Epoch time: 6321.725 ms, per step time: 3160.862 ms, avg loss: 0.473\n",
      "Epoch:[ 51/240], step:[    1/    2], loss:[0.470/0.470], time:2731.356 ms, lr:0.00086\n",
      "Epoch:[ 51/240], step:[    2/    2], loss:[0.473/0.471], time:2738.792 ms, lr:0.00086\n",
      "Train epoch time: 5490.194 ms, per step time: 2745.097 ms\n",
      "Epoch time: 5491.195 ms, per step time: 2745.598 ms, avg loss: 0.471\n",
      "Epoch:[ 52/240], step:[    1/    2], loss:[0.475/0.475], time:2530.665 ms, lr:0.00086\n",
      "Epoch:[ 52/240], step:[    2/    2], loss:[0.474/0.475], time:2559.757 ms, lr:0.00086\n",
      "Train epoch time: 5108.438 ms, per step time: 2554.219 ms\n",
      "Epoch time: 5109.439 ms, per step time: 2554.719 ms, avg loss: 0.475\n",
      "Epoch:[ 53/240], step:[    1/    2], loss:[0.473/0.473], time:2765.626 ms, lr:0.00085\n",
      "Epoch:[ 53/240], step:[    2/    2], loss:[0.470/0.471], time:2747.283 ms, lr:0.00085\n",
      "Train epoch time: 5534.928 ms, per step time: 2767.464 ms\n",
      "Epoch time: 5535.929 ms, per step time: 2767.965 ms, avg loss: 0.471\n",
      "Epoch:[ 54/240], step:[    1/    2], loss:[0.468/0.468], time:2755.123 ms, lr:0.00085\n",
      "Epoch:[ 54/240], step:[    2/    2], loss:[0.469/0.468], time:2671.725 ms, lr:0.00085\n",
      "Train epoch time: 5449.869 ms, per step time: 2724.935 ms\n",
      "Epoch time: 5450.870 ms, per step time: 2725.435 ms, avg loss: 0.468\n",
      "Epoch:[ 55/240], step:[    1/    2], loss:[0.467/0.467], time:2650.074 ms, lr:0.00084\n",
      "Epoch:[ 55/240], step:[    2/    2], loss:[0.467/0.467], time:2628.869 ms, lr:0.00084\n",
      "Train epoch time: 5298.953 ms, per step time: 2649.476 ms\n",
      "Epoch time: 5299.954 ms, per step time: 2649.977 ms, avg loss: 0.467\n",
      "Epoch:[ 56/240], step:[    1/    2], loss:[0.469/0.469], time:2606.333 ms, lr:0.00084\n",
      "Epoch:[ 56/240], step:[    2/    2], loss:[0.467/0.468], time:2613.921 ms, lr:0.00084\n",
      "Train epoch time: 5240.272 ms, per step time: 2620.136 ms\n",
      "Epoch time: 5241.273 ms, per step time: 2620.637 ms, avg loss: 0.468\n",
      "Epoch:[ 57/240], step:[    1/    2], loss:[0.471/0.471], time:2603.818 ms, lr:0.00083\n",
      "Epoch:[ 57/240], step:[    2/    2], loss:[0.466/0.469], time:2722.811 ms, lr:0.00083\n",
      "Train epoch time: 5349.650 ms, per step time: 2674.825 ms\n",
      "Epoch time: 5350.651 ms, per step time: 2675.325 ms, avg loss: 0.469\n",
      "Epoch:[ 58/240], step:[    1/    2], loss:[0.467/0.467], time:2723.149 ms, lr:0.00083\n",
      "Epoch:[ 58/240], step:[    2/    2], loss:[0.469/0.468], time:2760.949 ms, lr:0.00083\n",
      "Train epoch time: 5504.114 ms, per step time: 2752.057 ms\n",
      "Epoch time: 5505.115 ms, per step time: 2752.557 ms, avg loss: 0.468\n",
      "Epoch:[ 59/240], step:[    1/    2], loss:[0.469/0.469], time:2661.429 ms, lr:0.00082\n",
      "Epoch:[ 59/240], step:[    2/    2], loss:[0.467/0.468], time:2799.443 ms, lr:0.00082\n",
      "Train epoch time: 5733.933 ms, per step time: 2866.966 ms\n",
      "Epoch time: 5734.934 ms, per step time: 2867.467 ms, avg loss: 0.468\n",
      "Epoch:[ 60/240], step:[    1/    2], loss:[0.472/0.472], time:2714.245 ms, lr:0.00082\n",
      "Epoch:[ 60/240], step:[    2/    2], loss:[0.471/0.472], time:2707.191 ms, lr:0.00082\n",
      "Train epoch time: 5445.349 ms, per step time: 2722.674 ms\n",
      "Epoch time: 5446.350 ms, per step time: 2723.175 ms, avg loss: 0.472\n",
      "Epoch:[ 61/240], step:[    1/    2], loss:[0.481/0.481], time:2695.694 ms, lr:0.00081\n",
      "Epoch:[ 61/240], step:[    2/    2], loss:[0.467/0.474], time:2660.516 ms, lr:0.00081\n",
      "Train epoch time: 5378.230 ms, per step time: 2689.115 ms\n",
      "Epoch time: 5379.231 ms, per step time: 2689.615 ms, avg loss: 0.474\n",
      "Epoch:[ 62/240], step:[    1/    2], loss:[0.466/0.466], time:2515.108 ms, lr:0.00081\n",
      "Epoch:[ 62/240], step:[    2/    2], loss:[0.468/0.467], time:2545.336 ms, lr:0.00081\n",
      "Train epoch time: 5080.462 ms, per step time: 2540.231 ms\n",
      "Epoch time: 5081.464 ms, per step time: 2540.732 ms, avg loss: 0.467\n",
      "Epoch:[ 63/240], step:[    1/    2], loss:[0.469/0.469], time:2616.851 ms, lr:0.00080\n",
      "Epoch:[ 63/240], step:[    2/    2], loss:[0.471/0.470], time:2540.656 ms, lr:0.00080\n",
      "Train epoch time: 5177.525 ms, per step time: 2588.762 ms\n",
      "Epoch time: 5178.526 ms, per step time: 2589.263 ms, avg loss: 0.470\n",
      "Epoch:[ 64/240], step:[    1/    2], loss:[0.472/0.472], time:2475.483 ms, lr:0.00080\n",
      "Epoch:[ 64/240], step:[    2/    2], loss:[0.479/0.475], time:2488.950 ms, lr:0.00080\n",
      "Train epoch time: 4982.450 ms, per step time: 2491.225 ms\n",
      "Epoch time: 4983.451 ms, per step time: 2491.725 ms, avg loss: 0.475\n",
      "Epoch:[ 65/240], step:[    1/    2], loss:[0.467/0.467], time:2510.808 ms, lr:0.00079\n",
      "Epoch:[ 65/240], step:[    2/    2], loss:[0.472/0.470], time:2491.152 ms, lr:0.00079\n",
      "Train epoch time: 5021.979 ms, per step time: 2510.989 ms\n",
      "Epoch time: 5022.979 ms, per step time: 2511.490 ms, avg loss: 0.470\n",
      "Epoch:[ 66/240], step:[    1/    2], loss:[0.468/0.468], time:2543.590 ms, lr:0.00079\n",
      "Epoch:[ 66/240], step:[    2/    2], loss:[0.470/0.469], time:2785.359 ms, lr:0.00079\n",
      "Train epoch time: 5349.966 ms, per step time: 2674.983 ms\n",
      "Epoch time: 5350.967 ms, per step time: 2675.483 ms, avg loss: 0.469\n",
      "Epoch:[ 67/240], step:[    1/    2], loss:[0.471/0.471], time:2835.323 ms, lr:0.00078\n",
      "Epoch:[ 67/240], step:[    2/    2], loss:[0.470/0.471], time:2730.655 ms, lr:0.00078\n",
      "Train epoch time: 5587.990 ms, per step time: 2793.995 ms\n",
      "Epoch time: 5588.991 ms, per step time: 2794.495 ms, avg loss: 0.471\n",
      "Epoch:[ 68/240], step:[    1/    2], loss:[0.472/0.472], time:2858.375 ms, lr:0.00078\n",
      "Epoch:[ 68/240], step:[    2/    2], loss:[0.478/0.475], time:2728.046 ms, lr:0.00078\n",
      "Train epoch time: 5605.438 ms, per step time: 2802.719 ms\n",
      "Epoch time: 5606.440 ms, per step time: 2803.220 ms, avg loss: 0.475\n",
      "Epoch:[ 69/240], step:[    1/    2], loss:[0.473/0.473], time:2772.163 ms, lr:0.00077\n",
      "Epoch:[ 69/240], step:[    2/    2], loss:[0.469/0.471], time:2591.362 ms, lr:0.00077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch time: 5614.611 ms, per step time: 2807.306 ms\n",
      "Epoch time: 5615.612 ms, per step time: 2807.806 ms, avg loss: 0.471\n",
      "Epoch:[ 70/240], step:[    1/    2], loss:[0.469/0.469], time:2656.933 ms, lr:0.00077\n",
      "Epoch:[ 70/240], step:[    2/    2], loss:[0.472/0.470], time:3045.095 ms, lr:0.00077\n",
      "Train epoch time: 5723.046 ms, per step time: 2861.523 ms\n",
      "Epoch time: 5723.046 ms, per step time: 2861.523 ms, avg loss: 0.470\n",
      "Epoch:[ 71/240], step:[    1/    2], loss:[0.470/0.470], time:2893.305 ms, lr:0.00076\n",
      "Epoch:[ 71/240], step:[    2/    2], loss:[0.470/0.470], time:2887.393 ms, lr:0.00076\n",
      "Train epoch time: 5802.765 ms, per step time: 2901.383 ms\n",
      "Epoch time: 5803.767 ms, per step time: 2901.883 ms, avg loss: 0.470\n",
      "Epoch:[ 72/240], step:[    1/    2], loss:[0.471/0.471], time:2921.974 ms, lr:0.00076\n",
      "Epoch:[ 72/240], step:[    2/    2], loss:[0.472/0.471], time:2754.349 ms, lr:0.00076\n",
      "Train epoch time: 5696.339 ms, per step time: 2848.169 ms\n",
      "Epoch time: 5697.341 ms, per step time: 2848.670 ms, avg loss: 0.471\n",
      "Epoch:[ 73/240], step:[    1/    2], loss:[0.467/0.467], time:2740.981 ms, lr:0.00075\n",
      "Epoch:[ 73/240], step:[    2/    2], loss:[0.472/0.469], time:2664.006 ms, lr:0.00075\n",
      "Train epoch time: 5426.007 ms, per step time: 2713.004 ms\n",
      "Epoch time: 5427.008 ms, per step time: 2713.504 ms, avg loss: 0.469\n",
      "Epoch:[ 74/240], step:[    1/    2], loss:[0.467/0.467], time:2799.525 ms, lr:0.00075\n",
      "Epoch:[ 74/240], step:[    2/    2], loss:[0.472/0.470], time:2858.882 ms, lr:0.00075\n",
      "Train epoch time: 5680.428 ms, per step time: 2840.214 ms\n",
      "Epoch time: 5681.429 ms, per step time: 2840.715 ms, avg loss: 0.470\n",
      "Epoch:[ 75/240], step:[    1/    2], loss:[0.468/0.468], time:2560.625 ms, lr:0.00074\n",
      "Epoch:[ 75/240], step:[    2/    2], loss:[0.468/0.468], time:2826.555 ms, lr:0.00074\n",
      "Train epoch time: 5408.198 ms, per step time: 2704.099 ms\n",
      "Epoch time: 5409.199 ms, per step time: 2704.600 ms, avg loss: 0.468\n",
      "Epoch:[ 76/240], step:[    1/    2], loss:[0.468/0.468], time:3046.883 ms, lr:0.00074\n",
      "Epoch:[ 76/240], step:[    2/    2], loss:[0.468/0.468], time:2718.628 ms, lr:0.00074\n",
      "Train epoch time: 5785.622 ms, per step time: 2892.811 ms\n",
      "Epoch time: 5785.622 ms, per step time: 2892.811 ms, avg loss: 0.468\n",
      "Epoch:[ 77/240], step:[    1/    2], loss:[0.469/0.469], time:2640.701 ms, lr:0.00073\n",
      "Epoch:[ 77/240], step:[    2/    2], loss:[0.473/0.471], time:2572.448 ms, lr:0.00073\n",
      "Train epoch time: 5234.168 ms, per step time: 2617.084 ms\n",
      "Epoch time: 5235.169 ms, per step time: 2617.585 ms, avg loss: 0.471\n",
      "Epoch:[ 78/240], step:[    1/    2], loss:[0.470/0.470], time:2532.480 ms, lr:0.00072\n",
      "Epoch:[ 78/240], step:[    2/    2], loss:[0.469/0.469], time:2497.374 ms, lr:0.00072\n",
      "Train epoch time: 5049.869 ms, per step time: 2524.935 ms\n",
      "Epoch time: 5050.870 ms, per step time: 2525.435 ms, avg loss: 0.469\n",
      "Epoch:[ 79/240], step:[    1/    2], loss:[0.474/0.474], time:2531.889 ms, lr:0.00072\n",
      "Epoch:[ 79/240], step:[    2/    2], loss:[0.470/0.472], time:2513.524 ms, lr:0.00072\n",
      "Train epoch time: 5266.105 ms, per step time: 2633.053 ms\n",
      "Epoch time: 5267.106 ms, per step time: 2633.553 ms, avg loss: 0.472\n",
      "Epoch:[ 80/240], step:[    1/    2], loss:[0.467/0.467], time:2516.391 ms, lr:0.00071\n",
      "Epoch:[ 80/240], step:[    2/    2], loss:[0.467/0.467], time:2598.691 ms, lr:0.00071\n",
      "Train epoch time: 5134.790 ms, per step time: 2567.395 ms\n",
      "Epoch time: 5135.791 ms, per step time: 2567.896 ms, avg loss: 0.467\n",
      "Epoch:[ 81/240], step:[    1/    2], loss:[0.467/0.467], time:2503.362 ms, lr:0.00071\n",
      "Epoch:[ 81/240], step:[    2/    2], loss:[0.468/0.468], time:2521.243 ms, lr:0.00071\n",
      "Train epoch time: 5047.625 ms, per step time: 2523.812 ms\n",
      "Epoch time: 5048.626 ms, per step time: 2524.313 ms, avg loss: 0.468\n",
      "Epoch:[ 82/240], step:[    1/    2], loss:[0.466/0.466], time:2492.521 ms, lr:0.00070\n",
      "Epoch:[ 82/240], step:[    2/    2], loss:[0.471/0.469], time:2522.480 ms, lr:0.00070\n",
      "Train epoch time: 5037.021 ms, per step time: 2518.511 ms\n",
      "Epoch time: 5037.021 ms, per step time: 2518.511 ms, avg loss: 0.469\n",
      "Epoch:[ 83/240], step:[    1/    2], loss:[0.467/0.467], time:2739.646 ms, lr:0.00070\n",
      "Epoch:[ 83/240], step:[    2/    2], loss:[0.475/0.471], time:2523.657 ms, lr:0.00070\n",
      "Train epoch time: 5283.320 ms, per step time: 2641.660 ms\n",
      "Epoch time: 5284.321 ms, per step time: 2642.161 ms, avg loss: 0.471\n",
      "Epoch:[ 84/240], step:[    1/    2], loss:[0.471/0.471], time:2455.233 ms, lr:0.00069\n",
      "Epoch:[ 84/240], step:[    2/    2], loss:[0.466/0.469], time:2517.297 ms, lr:0.00069\n",
      "Train epoch time: 4991.547 ms, per step time: 2495.773 ms\n",
      "Epoch time: 4992.548 ms, per step time: 2496.274 ms, avg loss: 0.469\n",
      "Epoch:[ 85/240], step:[    1/    2], loss:[0.468/0.468], time:2482.337 ms, lr:0.00068\n",
      "Epoch:[ 85/240], step:[    2/    2], loss:[0.475/0.471], time:2504.043 ms, lr:0.00068\n",
      "Train epoch time: 5006.396 ms, per step time: 2503.198 ms\n",
      "Epoch time: 5007.398 ms, per step time: 2503.699 ms, avg loss: 0.471\n",
      "Epoch:[ 86/240], step:[    1/    2], loss:[0.469/0.469], time:2515.721 ms, lr:0.00068\n",
      "Epoch:[ 86/240], step:[    2/    2], loss:[0.467/0.468], time:2602.104 ms, lr:0.00068\n",
      "Train epoch time: 5137.842 ms, per step time: 2568.921 ms\n",
      "Epoch time: 5138.844 ms, per step time: 2569.422 ms, avg loss: 0.468\n",
      "Epoch:[ 87/240], step:[    1/    2], loss:[0.466/0.466], time:2488.095 ms, lr:0.00067\n",
      "Epoch:[ 87/240], step:[    2/    2], loss:[0.468/0.467], time:2484.429 ms, lr:0.00067\n",
      "Train epoch time: 4992.415 ms, per step time: 2496.207 ms\n",
      "Epoch time: 4993.416 ms, per step time: 2496.708 ms, avg loss: 0.467\n",
      "Epoch:[ 88/240], step:[    1/    2], loss:[0.466/0.466], time:2516.527 ms, lr:0.00067\n",
      "Epoch:[ 88/240], step:[    2/    2], loss:[0.470/0.468], time:2525.030 ms, lr:0.00067\n",
      "Train epoch time: 5061.572 ms, per step time: 2530.786 ms\n",
      "Epoch time: 5062.573 ms, per step time: 2531.286 ms, avg loss: 0.468\n",
      "Epoch:[ 89/240], step:[    1/    2], loss:[0.468/0.468], time:2499.868 ms, lr:0.00066\n",
      "Epoch:[ 89/240], step:[    2/    2], loss:[0.472/0.470], time:2530.788 ms, lr:0.00066\n",
      "Train epoch time: 5278.997 ms, per step time: 2639.499 ms\n",
      "Epoch time: 5279.999 ms, per step time: 2639.999 ms, avg loss: 0.470\n",
      "Epoch:[ 90/240], step:[    1/    2], loss:[0.466/0.466], time:2520.949 ms, lr:0.00065\n",
      "Epoch:[ 90/240], step:[    2/    2], loss:[0.466/0.466], time:2507.090 ms, lr:0.00065\n",
      "Train epoch time: 5047.695 ms, per step time: 2523.848 ms\n",
      "Epoch time: 5048.696 ms, per step time: 2524.348 ms, avg loss: 0.466\n",
      "Epoch:[ 91/240], step:[    1/    2], loss:[0.467/0.467], time:2514.076 ms, lr:0.00065\n",
      "Epoch:[ 91/240], step:[    2/    2], loss:[0.468/0.468], time:2570.890 ms, lr:0.00065\n",
      "Train epoch time: 5104.982 ms, per step time: 2552.491 ms\n",
      "Epoch time: 5105.984 ms, per step time: 2552.992 ms, avg loss: 0.468\n",
      "Epoch:[ 92/240], step:[    1/    2], loss:[0.466/0.466], time:2521.191 ms, lr:0.00064\n",
      "Epoch:[ 92/240], step:[    2/    2], loss:[0.466/0.466], time:2470.809 ms, lr:0.00064\n",
      "Train epoch time: 5010.017 ms, per step time: 2505.008 ms\n",
      "Epoch time: 5011.017 ms, per step time: 2505.509 ms, avg loss: 0.466\n",
      "Epoch:[ 93/240], step:[    1/    2], loss:[0.466/0.466], time:2549.782 ms, lr:0.00064\n",
      "Epoch:[ 93/240], step:[    2/    2], loss:[0.466/0.466], time:2674.226 ms, lr:0.00064\n",
      "Train epoch time: 5244.017 ms, per step time: 2622.009 ms\n",
      "Epoch time: 5245.019 ms, per step time: 2622.509 ms, avg loss: 0.466\n",
      "Epoch:[ 94/240], step:[    1/    2], loss:[0.471/0.471], time:2531.160 ms, lr:0.00063\n",
      "Epoch:[ 94/240], step:[    2/    2], loss:[0.467/0.469], time:2537.978 ms, lr:0.00063\n",
      "Train epoch time: 5089.156 ms, per step time: 2544.578 ms\n",
      "Epoch time: 5090.157 ms, per step time: 2545.079 ms, avg loss: 0.469\n",
      "Epoch:[ 95/240], step:[    1/    2], loss:[0.468/0.468], time:2537.330 ms, lr:0.00062\n",
      "Epoch:[ 95/240], step:[    2/    2], loss:[0.467/0.468], time:2543.449 ms, lr:0.00062\n",
      "Train epoch time: 5100.789 ms, per step time: 2550.395 ms\n",
      "Epoch time: 5101.790 ms, per step time: 2550.895 ms, avg loss: 0.468\n",
      "Epoch:[ 96/240], step:[    1/    2], loss:[0.466/0.466], time:2533.565 ms, lr:0.00062\n",
      "Epoch:[ 96/240], step:[    2/    2], loss:[0.469/0.468], time:2504.086 ms, lr:0.00062\n",
      "Train epoch time: 5057.575 ms, per step time: 2528.787 ms\n",
      "Epoch time: 5058.575 ms, per step time: 2529.288 ms, avg loss: 0.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 97/240], step:[    1/    2], loss:[0.476/0.476], time:2475.767 ms, lr:0.00061\n",
      "Epoch:[ 97/240], step:[    2/    2], loss:[0.479/0.478], time:3330.045 ms, lr:0.00061\n",
      "Train epoch time: 5825.815 ms, per step time: 2912.908 ms\n",
      "Epoch time: 5826.816 ms, per step time: 2913.408 ms, avg loss: 0.478\n",
      "Epoch:[ 98/240], step:[    1/    2], loss:[0.469/0.469], time:3167.845 ms, lr:0.00061\n",
      "Epoch:[ 98/240], step:[    2/    2], loss:[0.468/0.469], time:2806.574 ms, lr:0.00061\n",
      "Train epoch time: 5998.438 ms, per step time: 2999.219 ms\n",
      "Epoch time: 5998.438 ms, per step time: 2999.219 ms, avg loss: 0.469\n",
      "Epoch:[ 99/240], step:[    1/    2], loss:[0.470/0.470], time:2534.035 ms, lr:0.00060\n",
      "Epoch:[ 99/240], step:[    2/    2], loss:[0.471/0.470], time:2489.554 ms, lr:0.00060\n",
      "Train epoch time: 5292.093 ms, per step time: 2646.046 ms\n",
      "Epoch time: 5293.094 ms, per step time: 2646.547 ms, avg loss: 0.470\n",
      "Epoch:[100/240], step:[    1/    2], loss:[0.466/0.466], time:2541.437 ms, lr:0.00059\n",
      "Epoch:[100/240], step:[    2/    2], loss:[0.469/0.467], time:2543.957 ms, lr:0.00059\n",
      "Train epoch time: 5106.268 ms, per step time: 2553.134 ms\n",
      "Epoch time: 5107.269 ms, per step time: 2553.635 ms, avg loss: 0.467\n",
      "Epoch:[101/240], step:[    1/    2], loss:[0.466/0.466], time:2553.971 ms, lr:0.00059\n",
      "Epoch:[101/240], step:[    2/    2], loss:[0.468/0.467], time:2531.687 ms, lr:0.00059\n",
      "Train epoch time: 5107.678 ms, per step time: 2553.839 ms\n",
      "Epoch time: 5107.678 ms, per step time: 2553.839 ms, avg loss: 0.467\n",
      "Epoch:[102/240], step:[    1/    2], loss:[0.468/0.468], time:2477.557 ms, lr:0.00058\n",
      "Epoch:[102/240], step:[    2/    2], loss:[0.469/0.468], time:2508.286 ms, lr:0.00058\n",
      "Train epoch time: 5005.856 ms, per step time: 2502.928 ms\n",
      "Epoch time: 5006.857 ms, per step time: 2503.428 ms, avg loss: 0.468\n",
      "Epoch:[103/240], step:[    1/    2], loss:[0.468/0.468], time:2577.464 ms, lr:0.00058\n",
      "Epoch:[103/240], step:[    2/    2], loss:[0.467/0.467], time:2510.734 ms, lr:0.00058\n",
      "Train epoch time: 5110.216 ms, per step time: 2555.108 ms\n",
      "Epoch time: 5111.217 ms, per step time: 2555.609 ms, avg loss: 0.467\n",
      "Epoch:[104/240], step:[    1/    2], loss:[0.466/0.466], time:2536.410 ms, lr:0.00057\n",
      "Epoch:[104/240], step:[    2/    2], loss:[0.468/0.467], time:2550.585 ms, lr:0.00057\n",
      "Train epoch time: 5108.013 ms, per step time: 2554.007 ms\n",
      "Epoch time: 5108.013 ms, per step time: 2554.007 ms, avg loss: 0.467\n",
      "Epoch:[105/240], step:[    1/    2], loss:[0.468/0.468], time:2540.021 ms, lr:0.00056\n",
      "Epoch:[105/240], step:[    2/    2], loss:[0.467/0.467], time:2505.573 ms, lr:0.00056\n",
      "Train epoch time: 5067.613 ms, per step time: 2533.806 ms\n",
      "Epoch time: 5068.614 ms, per step time: 2534.307 ms, avg loss: 0.467\n",
      "Epoch:[106/240], step:[    1/    2], loss:[0.469/0.469], time:2539.217 ms, lr:0.00056\n",
      "Epoch:[106/240], step:[    2/    2], loss:[0.468/0.469], time:2516.552 ms, lr:0.00056\n",
      "Train epoch time: 5075.779 ms, per step time: 2537.889 ms\n",
      "Epoch time: 5076.780 ms, per step time: 2538.390 ms, avg loss: 0.469\n",
      "Epoch:[107/240], step:[    1/    2], loss:[0.468/0.468], time:2513.843 ms, lr:0.00055\n",
      "Epoch:[107/240], step:[    2/    2], loss:[0.469/0.469], time:2516.552 ms, lr:0.00055\n",
      "Train epoch time: 5052.413 ms, per step time: 2526.207 ms\n",
      "Epoch time: 5052.413 ms, per step time: 2526.207 ms, avg loss: 0.469\n",
      "Epoch:[108/240], step:[    1/    2], loss:[0.466/0.466], time:2524.444 ms, lr:0.00054\n",
      "Epoch:[108/240], step:[    2/    2], loss:[0.468/0.467], time:2513.307 ms, lr:0.00054\n",
      "Train epoch time: 5057.760 ms, per step time: 2528.880 ms\n",
      "Epoch time: 5058.761 ms, per step time: 2529.380 ms, avg loss: 0.467\n",
      "Epoch:[109/240], step:[    1/    2], loss:[0.468/0.468], time:2491.844 ms, lr:0.00054\n",
      "Epoch:[109/240], step:[    2/    2], loss:[0.467/0.467], time:2518.534 ms, lr:0.00054\n",
      "Train epoch time: 5288.678 ms, per step time: 2644.339 ms\n",
      "Epoch time: 5290.298 ms, per step time: 2645.149 ms, avg loss: 0.467\n",
      "Epoch:[110/240], step:[    1/    2], loss:[0.467/0.467], time:2490.600 ms, lr:0.00053\n",
      "Epoch:[110/240], step:[    2/    2], loss:[0.466/0.467], time:2488.620 ms, lr:0.00053\n",
      "Train epoch time: 4998.238 ms, per step time: 2499.119 ms\n",
      "Epoch time: 4999.239 ms, per step time: 2499.619 ms, avg loss: 0.467\n",
      "Epoch:[111/240], step:[    1/    2], loss:[0.468/0.468], time:2505.797 ms, lr:0.00053\n",
      "Epoch:[111/240], step:[    2/    2], loss:[0.468/0.468], time:2531.209 ms, lr:0.00053\n",
      "Train epoch time: 5056.022 ms, per step time: 2528.011 ms\n",
      "Epoch time: 5056.022 ms, per step time: 2528.011 ms, avg loss: 0.468\n",
      "Epoch:[112/240], step:[    1/    2], loss:[0.468/0.468], time:2492.282 ms, lr:0.00052\n",
      "Epoch:[112/240], step:[    2/    2], loss:[0.468/0.468], time:2507.954 ms, lr:0.00052\n",
      "Train epoch time: 5019.251 ms, per step time: 2509.625 ms\n",
      "Epoch time: 5020.252 ms, per step time: 2510.126 ms, avg loss: 0.468\n",
      "Epoch:[113/240], step:[    1/    2], loss:[0.466/0.466], time:2514.843 ms, lr:0.00051\n",
      "Epoch:[113/240], step:[    2/    2], loss:[0.465/0.465], time:2503.666 ms, lr:0.00051\n",
      "Train epoch time: 5038.526 ms, per step time: 2519.263 ms\n",
      "Epoch time: 5038.526 ms, per step time: 2519.263 ms, avg loss: 0.465\n",
      "Epoch:[114/240], step:[    1/    2], loss:[0.466/0.466], time:2554.605 ms, lr:0.00051\n",
      "Epoch:[114/240], step:[    2/    2], loss:[0.467/0.467], time:2519.814 ms, lr:0.00051\n",
      "Train epoch time: 5094.437 ms, per step time: 2547.219 ms\n",
      "Epoch time: 5094.437 ms, per step time: 2547.219 ms, avg loss: 0.467\n",
      "Epoch:[115/240], step:[    1/    2], loss:[0.467/0.467], time:2546.583 ms, lr:0.00050\n",
      "Epoch:[115/240], step:[    2/    2], loss:[0.466/0.466], time:2517.114 ms, lr:0.00050\n",
      "Train epoch time: 5082.798 ms, per step time: 2541.399 ms\n",
      "Epoch time: 5082.798 ms, per step time: 2541.399 ms, avg loss: 0.466\n",
      "Epoch:[116/240], step:[    1/    2], loss:[0.471/0.471], time:2521.770 ms, lr:0.00049\n",
      "Epoch:[116/240], step:[    2/    2], loss:[0.471/0.471], time:2470.408 ms, lr:0.00049\n",
      "Train epoch time: 5012.193 ms, per step time: 2506.097 ms\n",
      "Epoch time: 5013.195 ms, per step time: 2506.597 ms, avg loss: 0.471\n",
      "Epoch:[117/240], step:[    1/    2], loss:[0.468/0.468], time:2530.137 ms, lr:0.00049\n",
      "Epoch:[117/240], step:[    2/    2], loss:[0.468/0.468], time:2494.749 ms, lr:0.00049\n",
      "Train epoch time: 5043.902 ms, per step time: 2521.951 ms\n",
      "Epoch time: 5043.902 ms, per step time: 2521.951 ms, avg loss: 0.468\n",
      "Epoch:[118/240], step:[    1/    2], loss:[0.465/0.465], time:2518.898 ms, lr:0.00048\n",
      "Epoch:[118/240], step:[    2/    2], loss:[0.467/0.466], time:2531.818 ms, lr:0.00048\n",
      "Train epoch time: 5068.732 ms, per step time: 2534.366 ms\n",
      "Epoch time: 5069.733 ms, per step time: 2534.867 ms, avg loss: 0.466\n",
      "Epoch:[119/240], step:[    1/    2], loss:[0.467/0.467], time:2495.265 ms, lr:0.00047\n",
      "Epoch:[119/240], step:[    2/    2], loss:[0.465/0.466], time:2537.621 ms, lr:0.00047\n",
      "Train epoch time: 5248.753 ms, per step time: 2624.377 ms\n",
      "Epoch time: 5249.755 ms, per step time: 2624.877 ms, avg loss: 0.466\n",
      "Epoch:[120/240], step:[    1/    2], loss:[0.465/0.465], time:2473.121 ms, lr:0.00047\n",
      "Epoch:[120/240], step:[    2/    2], loss:[0.465/0.465], time:2513.513 ms, lr:0.00047\n",
      "Train epoch time: 5006.648 ms, per step time: 2503.324 ms\n",
      "Epoch time: 5007.649 ms, per step time: 2503.825 ms, avg loss: 0.465\n",
      "Epoch:[121/240], step:[    1/    2], loss:[0.466/0.466], time:2558.516 ms, lr:0.00046\n",
      "Epoch:[121/240], step:[    2/    2], loss:[0.467/0.466], time:2481.665 ms, lr:0.00046\n",
      "Train epoch time: 5060.194 ms, per step time: 2530.097 ms\n",
      "Epoch time: 5061.195 ms, per step time: 2530.597 ms, avg loss: 0.466\n",
      "Epoch:[122/240], step:[    1/    2], loss:[0.470/0.470], time:2517.399 ms, lr:0.00046\n",
      "Epoch:[122/240], step:[    2/    2], loss:[0.467/0.469], time:2544.242 ms, lr:0.00046\n",
      "Train epoch time: 5080.657 ms, per step time: 2540.329 ms\n",
      "Epoch time: 5081.659 ms, per step time: 2540.829 ms, avg loss: 0.469\n",
      "Epoch:[123/240], step:[    1/    2], loss:[0.465/0.465], time:2611.623 ms, lr:0.00045\n",
      "Epoch:[123/240], step:[    2/    2], loss:[0.467/0.466], time:2569.439 ms, lr:0.00045\n",
      "Train epoch time: 5201.075 ms, per step time: 2600.538 ms\n",
      "Epoch time: 5202.076 ms, per step time: 2601.038 ms, avg loss: 0.466\n",
      "Epoch:[124/240], step:[    1/    2], loss:[0.466/0.466], time:2583.368 ms, lr:0.00044\n",
      "Epoch:[124/240], step:[    2/    2], loss:[0.465/0.466], time:2571.083 ms, lr:0.00044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch time: 5173.464 ms, per step time: 2586.732 ms\n",
      "Epoch time: 5174.465 ms, per step time: 2587.232 ms, avg loss: 0.466\n",
      "Epoch:[125/240], step:[    1/    2], loss:[0.467/0.467], time:2513.672 ms, lr:0.00044\n",
      "Epoch:[125/240], step:[    2/    2], loss:[0.466/0.466], time:2493.711 ms, lr:0.00044\n",
      "Train epoch time: 5027.401 ms, per step time: 2513.700 ms\n",
      "Epoch time: 5028.402 ms, per step time: 2514.201 ms, avg loss: 0.466\n",
      "Epoch:[126/240], step:[    1/    2], loss:[0.466/0.466], time:2535.617 ms, lr:0.00043\n",
      "Epoch:[126/240], step:[    2/    2], loss:[0.466/0.466], time:2531.222 ms, lr:0.00043\n",
      "Train epoch time: 5084.855 ms, per step time: 2542.427 ms\n",
      "Epoch time: 5085.856 ms, per step time: 2542.928 ms, avg loss: 0.466\n",
      "Epoch:[127/240], step:[    1/    2], loss:[0.465/0.465], time:2555.778 ms, lr:0.00042\n",
      "Epoch:[127/240], step:[    2/    2], loss:[0.465/0.465], time:2584.415 ms, lr:0.00042\n",
      "Train epoch time: 5162.262 ms, per step time: 2581.131 ms\n",
      "Epoch time: 5162.262 ms, per step time: 2581.131 ms, avg loss: 0.465\n",
      "Epoch:[128/240], step:[    1/    2], loss:[0.467/0.467], time:2568.620 ms, lr:0.00042\n",
      "Epoch:[128/240], step:[    2/    2], loss:[0.469/0.468], time:2614.575 ms, lr:0.00042\n",
      "Train epoch time: 5202.213 ms, per step time: 2601.106 ms\n",
      "Epoch time: 5203.213 ms, per step time: 2601.606 ms, avg loss: 0.468\n",
      "Epoch:[129/240], step:[    1/    2], loss:[0.467/0.467], time:2570.187 ms, lr:0.00041\n",
      "Epoch:[129/240], step:[    2/    2], loss:[0.467/0.467], time:2644.502 ms, lr:0.00041\n",
      "Train epoch time: 5429.470 ms, per step time: 2714.735 ms\n",
      "Epoch time: 5430.470 ms, per step time: 2715.235 ms, avg loss: 0.467\n",
      "Epoch:[130/240], step:[    1/    2], loss:[0.468/0.468], time:4281.970 ms, lr:0.00041\n",
      "Epoch:[130/240], step:[    2/    2], loss:[0.471/0.469], time:5092.884 ms, lr:0.00041\n",
      "Train epoch time: 9394.936 ms, per step time: 4697.468 ms\n",
      "Epoch time: 9395.937 ms, per step time: 4697.968 ms, avg loss: 0.469\n",
      "Epoch:[131/240], step:[    1/    2], loss:[0.466/0.466], time:3786.403 ms, lr:0.00040\n",
      "Epoch:[131/240], step:[    2/    2], loss:[0.466/0.466], time:3508.718 ms, lr:0.00040\n",
      "Train epoch time: 7319.204 ms, per step time: 3659.602 ms\n",
      "Epoch time: 7320.204 ms, per step time: 3660.102 ms, avg loss: 0.466\n",
      "Epoch:[132/240], step:[    1/    2], loss:[0.468/0.468], time:3550.270 ms, lr:0.00039\n",
      "Epoch:[132/240], step:[    2/    2], loss:[0.470/0.469], time:3714.036 ms, lr:0.00039\n",
      "Train epoch time: 7285.325 ms, per step time: 3642.662 ms\n",
      "Epoch time: 7287.327 ms, per step time: 3643.663 ms, avg loss: 0.469\n",
      "Epoch:[133/240], step:[    1/    2], loss:[0.469/0.469], time:3689.568 ms, lr:0.00039\n",
      "Epoch:[133/240], step:[    2/    2], loss:[0.466/0.468], time:3757.954 ms, lr:0.00039\n",
      "Train epoch time: 7469.537 ms, per step time: 3734.769 ms\n",
      "Epoch time: 7470.539 ms, per step time: 3735.270 ms, avg loss: 0.468\n",
      "Epoch:[134/240], step:[    1/    2], loss:[0.467/0.467], time:3302.486 ms, lr:0.00038\n",
      "Epoch:[134/240], step:[    2/    2], loss:[0.465/0.466], time:3967.649 ms, lr:0.00038\n",
      "Train epoch time: 7292.149 ms, per step time: 3646.075 ms\n",
      "Epoch time: 7293.150 ms, per step time: 3646.575 ms, avg loss: 0.466\n",
      "Epoch:[135/240], step:[    1/    2], loss:[0.465/0.465], time:2854.213 ms, lr:0.00038\n",
      "Epoch:[135/240], step:[    2/    2], loss:[0.467/0.466], time:3953.072 ms, lr:0.00038\n",
      "Train epoch time: 6828.304 ms, per step time: 3414.152 ms\n",
      "Epoch time: 6829.304 ms, per step time: 3414.652 ms, avg loss: 0.466\n",
      "Epoch:[136/240], step:[    1/    2], loss:[0.466/0.466], time:3226.792 ms, lr:0.00037\n",
      "Epoch:[136/240], step:[    2/    2], loss:[0.466/0.466], time:3527.600 ms, lr:0.00037\n",
      "Train epoch time: 6778.403 ms, per step time: 3389.201 ms\n",
      "Epoch time: 6779.403 ms, per step time: 3389.702 ms, avg loss: 0.466\n",
      "Epoch:[137/240], step:[    1/    2], loss:[0.465/0.465], time:3390.055 ms, lr:0.00036\n",
      "Epoch:[137/240], step:[    2/    2], loss:[0.469/0.467], time:3155.747 ms, lr:0.00036\n",
      "Train epoch time: 6570.825 ms, per step time: 3285.413 ms\n",
      "Epoch time: 6572.827 ms, per step time: 3286.414 ms, avg loss: 0.467\n",
      "Epoch:[138/240], step:[    1/    2], loss:[0.467/0.467], time:3038.235 ms, lr:0.00036\n",
      "Epoch:[138/240], step:[    2/    2], loss:[0.469/0.468], time:3089.056 ms, lr:0.00036\n",
      "Train epoch time: 6153.314 ms, per step time: 3076.657 ms\n",
      "Epoch time: 6155.316 ms, per step time: 3077.658 ms, avg loss: 0.468\n",
      "Epoch:[139/240], step:[    1/    2], loss:[0.466/0.466], time:3072.997 ms, lr:0.00035\n",
      "Epoch:[139/240], step:[    2/    2], loss:[0.468/0.467], time:2759.115 ms, lr:0.00035\n",
      "Train epoch time: 6048.536 ms, per step time: 3024.268 ms\n",
      "Epoch time: 6049.537 ms, per step time: 3024.769 ms, avg loss: 0.467\n",
      "Epoch:[140/240], step:[    1/    2], loss:[0.468/0.468], time:2863.129 ms, lr:0.00035\n",
      "Epoch:[140/240], step:[    2/    2], loss:[0.467/0.468], time:3048.932 ms, lr:0.00035\n",
      "Train epoch time: 5932.819 ms, per step time: 2966.410 ms\n",
      "Epoch time: 5933.820 ms, per step time: 2966.910 ms, avg loss: 0.468\n",
      "Epoch:[141/240], step:[    1/    2], loss:[0.467/0.467], time:3050.620 ms, lr:0.00034\n",
      "Epoch:[141/240], step:[    2/    2], loss:[0.467/0.467], time:3053.682 ms, lr:0.00034\n",
      "Train epoch time: 6127.311 ms, per step time: 3063.655 ms\n",
      "Epoch time: 6128.312 ms, per step time: 3064.156 ms, avg loss: 0.467\n",
      "Epoch:[142/240], step:[    1/    2], loss:[0.471/0.471], time:3005.282 ms, lr:0.00033\n",
      "Epoch:[142/240], step:[    2/    2], loss:[0.468/0.470], time:3102.086 ms, lr:0.00033\n",
      "Train epoch time: 6129.388 ms, per step time: 3064.694 ms\n",
      "Epoch time: 6130.389 ms, per step time: 3065.195 ms, avg loss: 0.470\n",
      "Epoch:[143/240], step:[    1/    2], loss:[0.466/0.466], time:3042.204 ms, lr:0.00033\n",
      "Epoch:[143/240], step:[    2/    2], loss:[0.467/0.467], time:3036.891 ms, lr:0.00033\n",
      "Train epoch time: 6101.110 ms, per step time: 3050.555 ms\n",
      "Epoch time: 6102.110 ms, per step time: 3051.055 ms, avg loss: 0.467\n",
      "Epoch:[144/240], step:[    1/    2], loss:[0.467/0.467], time:3025.490 ms, lr:0.00032\n",
      "Epoch:[144/240], step:[    2/    2], loss:[0.466/0.467], time:3039.540 ms, lr:0.00032\n",
      "Train epoch time: 6090.052 ms, per step time: 3045.026 ms\n",
      "Epoch time: 6091.053 ms, per step time: 3045.527 ms, avg loss: 0.467\n",
      "Epoch:[145/240], step:[    1/    2], loss:[0.465/0.465], time:3022.493 ms, lr:0.00032\n",
      "Epoch:[145/240], step:[    2/    2], loss:[0.465/0.465], time:3067.983 ms, lr:0.00032\n",
      "Train epoch time: 6113.496 ms, per step time: 3056.748 ms\n",
      "Epoch time: 6114.497 ms, per step time: 3057.248 ms, avg loss: 0.465\n",
      "Epoch:[146/240], step:[    1/    2], loss:[0.465/0.465], time:3169.604 ms, lr:0.00031\n",
      "Epoch:[146/240], step:[    2/    2], loss:[0.468/0.467], time:3002.747 ms, lr:0.00031\n",
      "Train epoch time: 6193.369 ms, per step time: 3096.685 ms\n",
      "Epoch time: 6194.371 ms, per step time: 3097.185 ms, avg loss: 0.467\n",
      "Epoch:[147/240], step:[    1/    2], loss:[0.465/0.465], time:2679.354 ms, lr:0.00030\n",
      "Epoch:[147/240], step:[    2/    2], loss:[0.467/0.466], time:2671.433 ms, lr:0.00030\n",
      "Train epoch time: 5371.806 ms, per step time: 2685.903 ms\n",
      "Epoch time: 5371.806 ms, per step time: 2685.903 ms, avg loss: 0.466\n",
      "Epoch:[148/240], step:[    1/    2], loss:[0.465/0.465], time:2608.271 ms, lr:0.00030\n",
      "Epoch:[148/240], step:[    2/    2], loss:[0.466/0.465], time:2683.233 ms, lr:0.00030\n",
      "Train epoch time: 5313.524 ms, per step time: 2656.762 ms\n",
      "Epoch time: 5314.526 ms, per step time: 2657.263 ms, avg loss: 0.465\n",
      "Epoch:[149/240], step:[    1/    2], loss:[0.465/0.465], time:2627.764 ms, lr:0.00029\n",
      "Epoch:[149/240], step:[    2/    2], loss:[0.465/0.465], time:2833.852 ms, lr:0.00029\n",
      "Train epoch time: 5717.829 ms, per step time: 2858.914 ms\n",
      "Epoch time: 5718.830 ms, per step time: 2859.415 ms, avg loss: 0.465\n",
      "Epoch:[150/240], step:[    1/    2], loss:[0.465/0.465], time:2993.283 ms, lr:0.00029\n",
      "Epoch:[150/240], step:[    2/    2], loss:[0.466/0.465], time:2887.949 ms, lr:0.00029\n",
      "Train epoch time: 5905.115 ms, per step time: 2952.558 ms\n",
      "Epoch time: 5906.116 ms, per step time: 2953.058 ms, avg loss: 0.465\n",
      "Epoch:[151/240], step:[    1/    2], loss:[0.465/0.465], time:3320.301 ms, lr:0.00028\n",
      "Epoch:[151/240], step:[    2/    2], loss:[0.466/0.466], time:3298.500 ms, lr:0.00028\n",
      "Train epoch time: 6641.823 ms, per step time: 3320.911 ms\n",
      "Epoch time: 6643.481 ms, per step time: 3321.741 ms, avg loss: 0.466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[152/240], step:[    1/    2], loss:[0.467/0.467], time:3092.586 ms, lr:0.00028\n",
      "Epoch:[152/240], step:[    2/    2], loss:[0.469/0.468], time:3111.950 ms, lr:0.00028\n",
      "Train epoch time: 6225.536 ms, per step time: 3112.768 ms\n",
      "Epoch time: 6226.537 ms, per step time: 3113.268 ms, avg loss: 0.468\n",
      "Epoch:[153/240], step:[    1/    2], loss:[0.465/0.465], time:3257.188 ms, lr:0.00027\n",
      "Epoch:[153/240], step:[    2/    2], loss:[0.466/0.465], time:3141.823 ms, lr:0.00027\n",
      "Train epoch time: 6419.568 ms, per step time: 3209.784 ms\n",
      "Epoch time: 6420.568 ms, per step time: 3210.284 ms, avg loss: 0.465\n",
      "Epoch:[154/240], step:[    1/    2], loss:[0.465/0.465], time:3103.691 ms, lr:0.00026\n",
      "Epoch:[154/240], step:[    2/    2], loss:[0.466/0.466], time:3293.181 ms, lr:0.00026\n",
      "Train epoch time: 6416.890 ms, per step time: 3208.445 ms\n",
      "Epoch time: 6418.892 ms, per step time: 3209.446 ms, avg loss: 0.466\n",
      "Epoch:[155/240], step:[    1/    2], loss:[0.465/0.465], time:3740.847 ms, lr:0.00026\n",
      "Epoch:[155/240], step:[    2/    2], loss:[0.465/0.465], time:3080.717 ms, lr:0.00026\n",
      "Train epoch time: 6843.807 ms, per step time: 3421.904 ms\n",
      "Epoch time: 6844.808 ms, per step time: 3422.404 ms, avg loss: 0.465\n",
      "Epoch:[156/240], step:[    1/    2], loss:[0.465/0.465], time:3586.556 ms, lr:0.00025\n",
      "Epoch:[156/240], step:[    2/    2], loss:[0.465/0.465], time:3304.353 ms, lr:0.00025\n",
      "Train epoch time: 6915.601 ms, per step time: 3457.800 ms\n",
      "Epoch time: 6916.602 ms, per step time: 3458.301 ms, avg loss: 0.465\n",
      "Epoch:[157/240], step:[    1/    2], loss:[0.465/0.465], time:3345.772 ms, lr:0.00025\n",
      "Epoch:[157/240], step:[    2/    2], loss:[0.465/0.465], time:3332.970 ms, lr:0.00025\n",
      "Train epoch time: 6699.759 ms, per step time: 3349.880 ms\n",
      "Epoch time: 6701.761 ms, per step time: 3350.881 ms, avg loss: 0.465\n",
      "Epoch:[158/240], step:[    1/    2], loss:[0.468/0.468], time:3315.100 ms, lr:0.00024\n",
      "Epoch:[158/240], step:[    2/    2], loss:[0.466/0.467], time:3130.984 ms, lr:0.00024\n",
      "Train epoch time: 6469.105 ms, per step time: 3234.553 ms\n",
      "Epoch time: 6470.106 ms, per step time: 3235.053 ms, avg loss: 0.467\n",
      "Epoch:[159/240], step:[    1/    2], loss:[0.466/0.466], time:3340.458 ms, lr:0.00024\n",
      "Epoch:[159/240], step:[    2/    2], loss:[0.466/0.466], time:3405.789 ms, lr:0.00024\n",
      "Train epoch time: 6978.306 ms, per step time: 3489.153 ms\n",
      "Epoch time: 6979.307 ms, per step time: 3489.653 ms, avg loss: 0.466\n",
      "Epoch:[160/240], step:[    1/    2], loss:[0.465/0.465], time:3378.122 ms, lr:0.00023\n",
      "Epoch:[160/240], step:[    2/    2], loss:[0.465/0.465], time:3226.835 ms, lr:0.00023\n",
      "Train epoch time: 6629.968 ms, per step time: 3314.984 ms\n",
      "Epoch time: 6629.968 ms, per step time: 3314.984 ms, avg loss: 0.465\n",
      "Epoch:[161/240], step:[    1/    2], loss:[0.468/0.468], time:3282.362 ms, lr:0.00023\n",
      "Epoch:[161/240], step:[    2/    2], loss:[0.470/0.469], time:3242.105 ms, lr:0.00023\n",
      "Train epoch time: 6546.471 ms, per step time: 3273.236 ms\n",
      "Epoch time: 6547.473 ms, per step time: 3273.736 ms, avg loss: 0.469\n",
      "Epoch:[162/240], step:[    1/    2], loss:[0.465/0.465], time:3307.243 ms, lr:0.00022\n",
      "Epoch:[162/240], step:[    2/    2], loss:[0.466/0.466], time:3241.714 ms, lr:0.00022\n",
      "Train epoch time: 6571.979 ms, per step time: 3285.990 ms\n",
      "Epoch time: 6572.979 ms, per step time: 3286.490 ms, avg loss: 0.466\n",
      "Epoch:[163/240], step:[    1/    2], loss:[0.489/0.489], time:3250.645 ms, lr:0.00022\n",
      "Epoch:[163/240], step:[    2/    2], loss:[0.470/0.480], time:3366.971 ms, lr:0.00022\n",
      "Train epoch time: 6641.625 ms, per step time: 3320.812 ms\n",
      "Epoch time: 6642.626 ms, per step time: 3321.313 ms, avg loss: 0.480\n",
      "Epoch:[164/240], step:[    1/    2], loss:[0.465/0.465], time:3319.906 ms, lr:0.00021\n",
      "Epoch:[164/240], step:[    2/    2], loss:[0.465/0.465], time:3370.107 ms, lr:0.00021\n",
      "Train epoch time: 6713.417 ms, per step time: 3356.709 ms\n",
      "Epoch time: 6715.415 ms, per step time: 3357.707 ms, avg loss: 0.465\n",
      "Epoch:[165/240], step:[    1/    2], loss:[0.469/0.469], time:3433.130 ms, lr:0.00021\n",
      "Epoch:[165/240], step:[    2/    2], loss:[0.468/0.468], time:3387.985 ms, lr:0.00021\n",
      "Train epoch time: 6843.144 ms, per step time: 3421.572 ms\n",
      "Epoch time: 6844.145 ms, per step time: 3422.073 ms, avg loss: 0.468\n",
      "Epoch:[166/240], step:[    1/    2], loss:[0.465/0.465], time:3283.594 ms, lr:0.00020\n",
      "Epoch:[166/240], step:[    2/    2], loss:[0.469/0.467], time:3312.502 ms, lr:0.00020\n",
      "Train epoch time: 6619.115 ms, per step time: 3309.557 ms\n",
      "Epoch time: 6620.116 ms, per step time: 3310.058 ms, avg loss: 0.467\n",
      "Epoch:[167/240], step:[    1/    2], loss:[0.465/0.465], time:3245.310 ms, lr:0.00020\n",
      "Epoch:[167/240], step:[    2/    2], loss:[0.467/0.466], time:3300.559 ms, lr:0.00020\n",
      "Train epoch time: 6568.427 ms, per step time: 3284.214 ms\n",
      "Epoch time: 6569.428 ms, per step time: 3284.714 ms, avg loss: 0.466\n",
      "Epoch:[168/240], step:[    1/    2], loss:[0.467/0.467], time:3377.575 ms, lr:0.00019\n",
      "Epoch:[168/240], step:[    2/    2], loss:[0.466/0.466], time:3327.862 ms, lr:0.00019\n",
      "Train epoch time: 6728.246 ms, per step time: 3364.123 ms\n",
      "Epoch time: 6729.247 ms, per step time: 3364.623 ms, avg loss: 0.466\n",
      "Epoch:[169/240], step:[    1/    2], loss:[0.466/0.466], time:3284.501 ms, lr:0.00019\n",
      "Epoch:[169/240], step:[    2/    2], loss:[0.469/0.467], time:3284.080 ms, lr:0.00019\n",
      "Train epoch time: 6791.757 ms, per step time: 3395.879 ms\n",
      "Epoch time: 6792.758 ms, per step time: 3396.379 ms, avg loss: 0.467\n",
      "Epoch:[170/240], step:[    1/    2], loss:[0.465/0.465], time:3242.587 ms, lr:0.00018\n",
      "Epoch:[170/240], step:[    2/    2], loss:[0.466/0.466], time:3372.004 ms, lr:0.00018\n",
      "Train epoch time: 6637.789 ms, per step time: 3318.895 ms\n",
      "Epoch time: 6638.790 ms, per step time: 3319.395 ms, avg loss: 0.466\n",
      "Epoch:[171/240], step:[    1/    2], loss:[0.466/0.466], time:3294.819 ms, lr:0.00018\n",
      "Epoch:[171/240], step:[    2/    2], loss:[0.465/0.466], time:3252.159 ms, lr:0.00018\n",
      "Train epoch time: 6566.758 ms, per step time: 3283.379 ms\n",
      "Epoch time: 6567.759 ms, per step time: 3283.880 ms, avg loss: 0.466\n",
      "Epoch:[172/240], step:[    1/    2], loss:[0.470/0.470], time:3261.402 ms, lr:0.00017\n",
      "Epoch:[172/240], step:[    2/    2], loss:[0.465/0.467], time:3340.921 ms, lr:0.00017\n",
      "Train epoch time: 6622.431 ms, per step time: 3311.215 ms\n",
      "Epoch time: 6624.434 ms, per step time: 3312.217 ms, avg loss: 0.467\n",
      "Epoch:[173/240], step:[    1/    2], loss:[0.466/0.466], time:3218.399 ms, lr:0.00017\n",
      "Epoch:[173/240], step:[    2/    2], loss:[0.465/0.466], time:3225.505 ms, lr:0.00017\n",
      "Train epoch time: 6467.919 ms, per step time: 3233.959 ms\n",
      "Epoch time: 6468.920 ms, per step time: 3234.460 ms, avg loss: 0.466\n",
      "Epoch:[174/240], step:[    1/    2], loss:[0.466/0.466], time:3318.666 ms, lr:0.00016\n",
      "Epoch:[174/240], step:[    2/    2], loss:[0.466/0.466], time:3219.340 ms, lr:0.00016\n",
      "Train epoch time: 6560.024 ms, per step time: 3280.012 ms\n",
      "Epoch time: 6561.026 ms, per step time: 3280.513 ms, avg loss: 0.466\n",
      "Epoch:[175/240], step:[    1/    2], loss:[0.469/0.469], time:3233.390 ms, lr:0.00016\n",
      "Epoch:[175/240], step:[    2/    2], loss:[0.466/0.467], time:3300.704 ms, lr:0.00016\n",
      "Train epoch time: 6556.169 ms, per step time: 3278.084 ms\n",
      "Epoch time: 6557.170 ms, per step time: 3278.585 ms, avg loss: 0.467\n",
      "Epoch:[176/240], step:[    1/    2], loss:[0.466/0.466], time:3180.238 ms, lr:0.00015\n",
      "Epoch:[176/240], step:[    2/    2], loss:[0.467/0.466], time:3088.818 ms, lr:0.00015\n",
      "Train epoch time: 6291.075 ms, per step time: 3145.537 ms\n",
      "Epoch time: 6292.076 ms, per step time: 3146.038 ms, avg loss: 0.466\n",
      "Epoch:[177/240], step:[    1/    2], loss:[0.466/0.466], time:3169.156 ms, lr:0.00015\n",
      "Epoch:[177/240], step:[    2/    2], loss:[0.466/0.466], time:3215.226 ms, lr:0.00015\n",
      "Train epoch time: 6407.397 ms, per step time: 3203.699 ms\n",
      "Epoch time: 6409.399 ms, per step time: 3204.699 ms, avg loss: 0.466\n",
      "Epoch:[178/240], step:[    1/    2], loss:[0.465/0.465], time:3195.876 ms, lr:0.00014\n",
      "Epoch:[178/240], step:[    2/    2], loss:[0.470/0.468], time:3223.223 ms, lr:0.00014\n",
      "Train epoch time: 6442.125 ms, per step time: 3221.063 ms\n",
      "Epoch time: 6443.126 ms, per step time: 3221.563 ms, avg loss: 0.468\n",
      "Epoch:[179/240], step:[    1/    2], loss:[0.466/0.466], time:3191.966 ms, lr:0.00014\n",
      "Epoch:[179/240], step:[    2/    2], loss:[0.466/0.466], time:3154.871 ms, lr:0.00014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch time: 6566.323 ms, per step time: 3283.162 ms\n",
      "Epoch time: 6568.325 ms, per step time: 3284.162 ms, avg loss: 0.466\n",
      "Epoch:[180/240], step:[    1/    2], loss:[0.466/0.466], time:3189.067 ms, lr:0.00014\n",
      "Epoch:[180/240], step:[    2/    2], loss:[0.468/0.467], time:3105.118 ms, lr:0.00014\n",
      "Train epoch time: 6318.256 ms, per step time: 3159.128 ms\n",
      "Epoch time: 6319.257 ms, per step time: 3159.628 ms, avg loss: 0.467\n",
      "Epoch:[181/240], step:[    1/    2], loss:[0.467/0.467], time:3238.214 ms, lr:0.00013\n",
      "Epoch:[181/240], step:[    2/    2], loss:[0.468/0.468], time:3244.334 ms, lr:0.00013\n",
      "Train epoch time: 6504.554 ms, per step time: 3252.277 ms\n",
      "Epoch time: 6505.555 ms, per step time: 3252.777 ms, avg loss: 0.468\n",
      "Epoch:[182/240], step:[    1/    2], loss:[0.466/0.466], time:3229.640 ms, lr:0.00013\n",
      "Epoch:[182/240], step:[    2/    2], loss:[0.466/0.466], time:3353.150 ms, lr:0.00013\n",
      "Train epoch time: 6603.809 ms, per step time: 3301.904 ms\n",
      "Epoch time: 6604.810 ms, per step time: 3302.405 ms, avg loss: 0.466\n",
      "Epoch:[183/240], step:[    1/    2], loss:[0.466/0.466], time:3278.007 ms, lr:0.00012\n",
      "Epoch:[183/240], step:[    2/    2], loss:[0.466/0.466], time:3359.113 ms, lr:0.00012\n",
      "Train epoch time: 6660.134 ms, per step time: 3330.067 ms\n",
      "Epoch time: 6661.135 ms, per step time: 3330.567 ms, avg loss: 0.466\n",
      "Epoch:[184/240], step:[    1/    2], loss:[0.465/0.465], time:3298.691 ms, lr:0.00012\n",
      "Epoch:[184/240], step:[    2/    2], loss:[0.466/0.465], time:3325.604 ms, lr:0.00012\n",
      "Train epoch time: 6645.314 ms, per step time: 3322.657 ms\n",
      "Epoch time: 6646.315 ms, per step time: 3323.158 ms, avg loss: 0.465\n",
      "Epoch:[185/240], step:[    1/    2], loss:[0.467/0.467], time:3358.888 ms, lr:0.00011\n",
      "Epoch:[185/240], step:[    2/    2], loss:[0.468/0.467], time:3543.435 ms, lr:0.00011\n",
      "Train epoch time: 6926.343 ms, per step time: 3463.172 ms\n",
      "Epoch time: 6927.344 ms, per step time: 3463.672 ms, avg loss: 0.467\n",
      "Epoch:[186/240], step:[    1/    2], loss:[0.464/0.464], time:3493.027 ms, lr:0.00011\n",
      "Epoch:[186/240], step:[    2/    2], loss:[0.467/0.466], time:3231.769 ms, lr:0.00011\n",
      "Train epoch time: 6748.818 ms, per step time: 3374.409 ms\n",
      "Epoch time: 6749.819 ms, per step time: 3374.910 ms, avg loss: 0.466\n",
      "Epoch:[187/240], step:[    1/    2], loss:[0.465/0.465], time:2815.592 ms, lr:0.00011\n",
      "Epoch:[187/240], step:[    2/    2], loss:[0.466/0.465], time:3742.648 ms, lr:0.00011\n",
      "Train epoch time: 6578.259 ms, per step time: 3289.129 ms\n",
      "Epoch time: 6579.260 ms, per step time: 3289.630 ms, avg loss: 0.465\n",
      "Epoch:[188/240], step:[    1/    2], loss:[0.465/0.465], time:3448.452 ms, lr:0.00010\n",
      "Epoch:[188/240], step:[    2/    2], loss:[0.467/0.466], time:3395.475 ms, lr:0.00010\n",
      "Train epoch time: 6866.630 ms, per step time: 3433.315 ms\n",
      "Epoch time: 6868.632 ms, per step time: 3434.316 ms, avg loss: 0.466\n",
      "Epoch:[189/240], step:[    1/    2], loss:[0.466/0.466], time:3364.334 ms, lr:0.00010\n",
      "Epoch:[189/240], step:[    2/    2], loss:[0.470/0.468], time:3397.473 ms, lr:0.00010\n",
      "Train epoch time: 6987.664 ms, per step time: 3493.832 ms\n",
      "Epoch time: 6989.666 ms, per step time: 3494.833 ms, avg loss: 0.468\n",
      "Epoch:[190/240], step:[    1/    2], loss:[0.466/0.466], time:3421.122 ms, lr:0.00010\n",
      "Epoch:[190/240], step:[    2/    2], loss:[0.467/0.467], time:3455.770 ms, lr:0.00010\n",
      "Train epoch time: 6899.923 ms, per step time: 3449.962 ms\n",
      "Epoch time: 6900.914 ms, per step time: 3450.457 ms, avg loss: 0.467\n",
      "Epoch:[191/240], step:[    1/    2], loss:[0.466/0.466], time:3395.333 ms, lr:0.00009\n",
      "Epoch:[191/240], step:[    2/    2], loss:[0.466/0.466], time:3282.242 ms, lr:0.00009\n",
      "Train epoch time: 6700.583 ms, per step time: 3350.292 ms\n",
      "Epoch time: 6701.584 ms, per step time: 3350.792 ms, avg loss: 0.466\n",
      "Epoch:[192/240], step:[    1/    2], loss:[0.467/0.467], time:3358.684 ms, lr:0.00009\n",
      "Epoch:[192/240], step:[    2/    2], loss:[0.467/0.467], time:3368.261 ms, lr:0.00009\n",
      "Train epoch time: 6748.954 ms, per step time: 3374.477 ms\n",
      "Epoch time: 6749.955 ms, per step time: 3374.978 ms, avg loss: 0.467\n",
      "Epoch:[193/240], step:[    1/    2], loss:[0.469/0.469], time:3468.900 ms, lr:0.00008\n",
      "Epoch:[193/240], step:[    2/    2], loss:[0.465/0.467], time:3242.882 ms, lr:0.00008\n",
      "Train epoch time: 6736.806 ms, per step time: 3368.403 ms\n",
      "Epoch time: 6738.808 ms, per step time: 3369.404 ms, avg loss: 0.467\n",
      "Epoch:[194/240], step:[    1/    2], loss:[0.465/0.465], time:3280.104 ms, lr:0.00008\n",
      "Epoch:[194/240], step:[    2/    2], loss:[0.466/0.465], time:3274.302 ms, lr:0.00008\n",
      "Train epoch time: 6579.422 ms, per step time: 3289.711 ms\n",
      "Epoch time: 6582.526 ms, per step time: 3291.263 ms, avg loss: 0.465\n",
      "Epoch:[195/240], step:[    1/    2], loss:[0.465/0.465], time:3315.264 ms, lr:0.00008\n",
      "Epoch:[195/240], step:[    2/    2], loss:[0.465/0.465], time:3269.500 ms, lr:0.00008\n",
      "Train epoch time: 6607.785 ms, per step time: 3303.892 ms\n",
      "Epoch time: 6609.787 ms, per step time: 3304.894 ms, avg loss: 0.465\n",
      "Epoch:[196/240], step:[    1/    2], loss:[0.465/0.465], time:3323.377 ms, lr:0.00007\n",
      "Epoch:[196/240], step:[    2/    2], loss:[0.466/0.465], time:3253.836 ms, lr:0.00007\n",
      "Train epoch time: 6604.223 ms, per step time: 3302.112 ms\n",
      "Epoch time: 6605.224 ms, per step time: 3302.612 ms, avg loss: 0.465\n",
      "Epoch:[197/240], step:[    1/    2], loss:[0.465/0.465], time:3379.976 ms, lr:0.00007\n",
      "Epoch:[197/240], step:[    2/    2], loss:[0.465/0.465], time:3339.556 ms, lr:0.00007\n",
      "Train epoch time: 6742.618 ms, per step time: 3371.309 ms\n",
      "Epoch time: 6743.618 ms, per step time: 3371.809 ms, avg loss: 0.465\n",
      "Epoch:[198/240], step:[    1/    2], loss:[0.465/0.465], time:3287.534 ms, lr:0.00007\n",
      "Epoch:[198/240], step:[    2/    2], loss:[0.466/0.465], time:3333.987 ms, lr:0.00007\n",
      "Train epoch time: 6645.543 ms, per step time: 3322.772 ms\n",
      "Epoch time: 6646.544 ms, per step time: 3323.272 ms, avg loss: 0.465\n",
      "Epoch:[199/240], step:[    1/    2], loss:[0.465/0.465], time:3262.614 ms, lr:0.00006\n",
      "Epoch:[199/240], step:[    2/    2], loss:[0.465/0.465], time:3370.414 ms, lr:0.00006\n",
      "Train epoch time: 6859.076 ms, per step time: 3429.538 ms\n",
      "Epoch time: 6860.076 ms, per step time: 3430.038 ms, avg loss: 0.465\n",
      "Epoch:[200/240], step:[    1/    2], loss:[0.465/0.465], time:3419.385 ms, lr:0.00006\n",
      "Epoch:[200/240], step:[    2/    2], loss:[0.465/0.465], time:3180.881 ms, lr:0.00006\n",
      "Train epoch time: 6620.336 ms, per step time: 3310.168 ms\n",
      "Epoch time: 6621.283 ms, per step time: 3310.642 ms, avg loss: 0.465\n",
      "Epoch:[201/240], step:[    1/    2], loss:[0.464/0.464], time:3300.673 ms, lr:0.00006\n",
      "Epoch:[201/240], step:[    2/    2], loss:[0.465/0.465], time:3315.485 ms, lr:0.00006\n",
      "Train epoch time: 6642.183 ms, per step time: 3321.091 ms\n",
      "Epoch time: 6643.183 ms, per step time: 3321.592 ms, avg loss: 0.465\n",
      "Epoch:[202/240], step:[    1/    2], loss:[0.465/0.465], time:3181.360 ms, lr:0.00006\n",
      "Epoch:[202/240], step:[    2/    2], loss:[0.465/0.465], time:3349.479 ms, lr:0.00006\n",
      "Train epoch time: 6552.858 ms, per step time: 3276.429 ms\n",
      "Epoch time: 6554.861 ms, per step time: 3277.430 ms, avg loss: 0.465\n",
      "Epoch:[203/240], step:[    1/    2], loss:[0.466/0.466], time:3203.320 ms, lr:0.00005\n",
      "Epoch:[203/240], step:[    2/    2], loss:[0.464/0.465], time:3109.945 ms, lr:0.00005\n",
      "Train epoch time: 6338.529 ms, per step time: 3169.264 ms\n",
      "Epoch time: 6339.530 ms, per step time: 3169.765 ms, avg loss: 0.465\n",
      "Epoch:[204/240], step:[    1/    2], loss:[0.464/0.464], time:3286.867 ms, lr:0.00005\n",
      "Epoch:[204/240], step:[    2/    2], loss:[0.464/0.464], time:3746.686 ms, lr:0.00005\n",
      "Train epoch time: 7057.546 ms, per step time: 3528.773 ms\n",
      "Epoch time: 7059.547 ms, per step time: 3529.774 ms, avg loss: 0.464\n",
      "Epoch:[205/240], step:[    1/    2], loss:[0.464/0.464], time:4131.618 ms, lr:0.00005\n",
      "Epoch:[205/240], step:[    2/    2], loss:[0.464/0.464], time:3820.891 ms, lr:0.00005\n",
      "Train epoch time: 7975.616 ms, per step time: 3987.808 ms\n",
      "Epoch time: 7976.617 ms, per step time: 3988.308 ms, avg loss: 0.464\n",
      "Epoch:[206/240], step:[    1/    2], loss:[0.466/0.466], time:3185.089 ms, lr:0.00004\n",
      "Epoch:[206/240], step:[    2/    2], loss:[0.473/0.469], time:3262.197 ms, lr:0.00004\n",
      "Train epoch time: 6470.294 ms, per step time: 3235.147 ms\n",
      "Epoch time: 6471.295 ms, per step time: 3235.647 ms, avg loss: 0.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[207/240], step:[    1/    2], loss:[0.464/0.464], time:3251.417 ms, lr:0.00004\n",
      "Epoch:[207/240], step:[    2/    2], loss:[0.465/0.465], time:3310.607 ms, lr:0.00004\n",
      "Train epoch time: 6587.047 ms, per step time: 3293.524 ms\n",
      "Epoch time: 6588.048 ms, per step time: 3294.024 ms, avg loss: 0.465\n",
      "Epoch:[208/240], step:[    1/    2], loss:[0.465/0.465], time:3240.446 ms, lr:0.00004\n",
      "Epoch:[208/240], step:[    2/    2], loss:[0.464/0.465], time:3311.095 ms, lr:0.00004\n",
      "Train epoch time: 6572.631 ms, per step time: 3286.315 ms\n",
      "Epoch time: 6574.633 ms, per step time: 3287.316 ms, avg loss: 0.465\n",
      "Epoch:[209/240], step:[    1/    2], loss:[0.464/0.464], time:3178.106 ms, lr:0.00004\n",
      "Epoch:[209/240], step:[    2/    2], loss:[0.466/0.465], time:3331.935 ms, lr:0.00004\n",
      "Train epoch time: 6733.831 ms, per step time: 3366.915 ms\n",
      "Epoch time: 6734.833 ms, per step time: 3367.416 ms, avg loss: 0.465\n",
      "Epoch:[210/240], step:[    1/    2], loss:[0.465/0.465], time:3361.317 ms, lr:0.00004\n",
      "Epoch:[210/240], step:[    2/    2], loss:[0.465/0.465], time:3402.342 ms, lr:0.00004\n",
      "Train epoch time: 6783.677 ms, per step time: 3391.839 ms\n",
      "Epoch time: 6784.678 ms, per step time: 3392.339 ms, avg loss: 0.465\n",
      "Epoch:[211/240], step:[    1/    2], loss:[0.466/0.466], time:3333.803 ms, lr:0.00003\n",
      "Epoch:[211/240], step:[    2/    2], loss:[0.465/0.465], time:3301.920 ms, lr:0.00003\n",
      "Train epoch time: 6659.746 ms, per step time: 3329.873 ms\n",
      "Epoch time: 6660.747 ms, per step time: 3330.374 ms, avg loss: 0.465\n",
      "Epoch:[212/240], step:[    1/    2], loss:[0.466/0.466], time:3277.015 ms, lr:0.00003\n",
      "Epoch:[212/240], step:[    2/    2], loss:[0.464/0.465], time:3178.883 ms, lr:0.00003\n",
      "Train epoch time: 6476.916 ms, per step time: 3238.458 ms\n",
      "Epoch time: 6477.916 ms, per step time: 3238.958 ms, avg loss: 0.465\n",
      "Epoch:[213/240], step:[    1/    2], loss:[0.465/0.465], time:3139.588 ms, lr:0.00003\n",
      "Epoch:[213/240], step:[    2/    2], loss:[0.465/0.465], time:3170.859 ms, lr:0.00003\n",
      "Train epoch time: 6332.467 ms, per step time: 3166.234 ms\n",
      "Epoch time: 6334.469 ms, per step time: 3167.234 ms, avg loss: 0.465\n",
      "Epoch:[214/240], step:[    1/    2], loss:[0.465/0.465], time:3543.757 ms, lr:0.00003\n",
      "Epoch:[214/240], step:[    2/    2], loss:[0.465/0.465], time:3797.049 ms, lr:0.00003\n",
      "Train epoch time: 7363.402 ms, per step time: 3681.701 ms\n",
      "Epoch time: 7364.403 ms, per step time: 3682.201 ms, avg loss: 0.465\n",
      "Epoch:[215/240], step:[    1/    2], loss:[0.465/0.465], time:3299.335 ms, lr:0.00002\n",
      "Epoch:[215/240], step:[    2/    2], loss:[0.465/0.465], time:3248.460 ms, lr:0.00002\n",
      "Train epoch time: 6570.815 ms, per step time: 3285.408 ms\n",
      "Epoch time: 6571.816 ms, per step time: 3285.908 ms, avg loss: 0.465\n",
      "Epoch:[216/240], step:[    1/    2], loss:[0.464/0.464], time:3241.179 ms, lr:0.00002\n",
      "Epoch:[216/240], step:[    2/    2], loss:[0.464/0.464], time:3128.394 ms, lr:0.00002\n",
      "Train epoch time: 6391.592 ms, per step time: 3195.796 ms\n",
      "Epoch time: 6392.593 ms, per step time: 3196.297 ms, avg loss: 0.464\n",
      "Epoch:[217/240], step:[    1/    2], loss:[0.465/0.465], time:3275.391 ms, lr:0.00002\n",
      "Epoch:[217/240], step:[    2/    2], loss:[0.465/0.465], time:3189.256 ms, lr:0.00002\n",
      "Train epoch time: 6486.659 ms, per step time: 3243.329 ms\n",
      "Epoch time: 6487.659 ms, per step time: 3243.830 ms, avg loss: 0.465\n",
      "Epoch:[218/240], step:[    1/    2], loss:[0.471/0.471], time:3181.549 ms, lr:0.00002\n",
      "Epoch:[218/240], step:[    2/    2], loss:[0.469/0.470], time:3811.660 ms, lr:0.00002\n",
      "Train epoch time: 7015.821 ms, per step time: 3507.910 ms\n",
      "Epoch time: 7018.824 ms, per step time: 3509.412 ms, avg loss: 0.470\n",
      "Epoch:[219/240], step:[    1/    2], loss:[0.464/0.464], time:3662.977 ms, lr:0.00002\n",
      "Epoch:[219/240], step:[    2/    2], loss:[0.464/0.464], time:3383.740 ms, lr:0.00002\n",
      "Train epoch time: 7274.299 ms, per step time: 3637.149 ms\n",
      "Epoch time: 7275.299 ms, per step time: 3637.650 ms, avg loss: 0.464\n",
      "Epoch:[220/240], step:[    1/    2], loss:[0.466/0.466], time:3256.470 ms, lr:0.00002\n",
      "Epoch:[220/240], step:[    2/    2], loss:[0.467/0.466], time:3323.069 ms, lr:0.00002\n",
      "Train epoch time: 6602.561 ms, per step time: 3301.281 ms\n",
      "Epoch time: 6603.562 ms, per step time: 3301.781 ms, avg loss: 0.466\n",
      "Epoch:[221/240], step:[    1/    2], loss:[0.465/0.465], time:3231.670 ms, lr:0.00001\n",
      "Epoch:[221/240], step:[    2/    2], loss:[0.465/0.465], time:3419.102 ms, lr:0.00001\n",
      "Train epoch time: 6671.791 ms, per step time: 3335.896 ms\n",
      "Epoch time: 6673.794 ms, per step time: 3336.897 ms, avg loss: 0.465\n",
      "Epoch:[222/240], step:[    1/    2], loss:[0.466/0.466], time:3548.849 ms, lr:0.00001\n",
      "Epoch:[222/240], step:[    2/    2], loss:[0.465/0.465], time:3411.730 ms, lr:0.00001\n",
      "Train epoch time: 6984.599 ms, per step time: 3492.299 ms\n",
      "Epoch time: 6985.600 ms, per step time: 3492.800 ms, avg loss: 0.465\n",
      "Epoch:[223/240], step:[    1/    2], loss:[0.465/0.465], time:3356.043 ms, lr:0.00001\n",
      "Epoch:[223/240], step:[    2/    2], loss:[0.465/0.465], time:3336.459 ms, lr:0.00001\n",
      "Train epoch time: 6715.522 ms, per step time: 3357.761 ms\n",
      "Epoch time: 6716.523 ms, per step time: 3358.262 ms, avg loss: 0.465\n",
      "Epoch:[224/240], step:[    1/    2], loss:[0.465/0.465], time:3253.496 ms, lr:0.00001\n",
      "Epoch:[224/240], step:[    2/    2], loss:[0.465/0.465], time:3175.671 ms, lr:0.00001\n",
      "Train epoch time: 6453.190 ms, per step time: 3226.595 ms\n",
      "Epoch time: 6454.191 ms, per step time: 3227.096 ms, avg loss: 0.465\n",
      "Epoch:[225/240], step:[    1/    2], loss:[0.467/0.467], time:3288.834 ms, lr:0.00001\n",
      "Epoch:[225/240], step:[    2/    2], loss:[0.469/0.468], time:3182.106 ms, lr:0.00001\n",
      "Train epoch time: 6497.965 ms, per step time: 3248.982 ms\n",
      "Epoch time: 6497.965 ms, per step time: 3248.982 ms, avg loss: 0.468\n",
      "Epoch:[226/240], step:[    1/    2], loss:[0.465/0.465], time:3321.271 ms, lr:0.00001\n",
      "Epoch:[226/240], step:[    2/    2], loss:[0.464/0.465], time:3343.881 ms, lr:0.00001\n",
      "Train epoch time: 6688.164 ms, per step time: 3344.082 ms\n",
      "Epoch time: 6689.165 ms, per step time: 3344.583 ms, avg loss: 0.465\n",
      "Epoch:[227/240], step:[    1/    2], loss:[0.464/0.464], time:3314.682 ms, lr:0.00001\n",
      "Epoch:[227/240], step:[    2/    2], loss:[0.464/0.464], time:3461.308 ms, lr:0.00001\n",
      "Train epoch time: 6796.000 ms, per step time: 3398.000 ms\n",
      "Epoch time: 6797.003 ms, per step time: 3398.501 ms, avg loss: 0.464\n",
      "Epoch:[228/240], step:[    1/    2], loss:[0.465/0.465], time:3756.639 ms, lr:0.00001\n",
      "Epoch:[228/240], step:[    2/    2], loss:[0.466/0.466], time:3294.083 ms, lr:0.00001\n",
      "Train epoch time: 7072.742 ms, per step time: 3536.371 ms\n",
      "Epoch time: 7073.743 ms, per step time: 3536.872 ms, avg loss: 0.466\n",
      "Epoch:[229/240], step:[    1/    2], loss:[0.465/0.465], time:3433.726 ms, lr:0.00000\n",
      "Epoch:[229/240], step:[    2/    2], loss:[0.467/0.466], time:3430.073 ms, lr:0.00000\n",
      "Train epoch time: 7092.466 ms, per step time: 3546.233 ms\n",
      "Epoch time: 7093.467 ms, per step time: 3546.733 ms, avg loss: 0.466\n",
      "Epoch:[230/240], step:[    1/    2], loss:[0.465/0.465], time:3391.481 ms, lr:0.00000\n",
      "Epoch:[230/240], step:[    2/    2], loss:[0.467/0.466], time:3334.819 ms, lr:0.00000\n",
      "Train epoch time: 6747.415 ms, per step time: 3373.707 ms\n",
      "Epoch time: 6748.415 ms, per step time: 3374.208 ms, avg loss: 0.466\n",
      "Epoch:[231/240], step:[    1/    2], loss:[0.465/0.465], time:3336.415 ms, lr:0.00000\n",
      "Epoch:[231/240], step:[    2/    2], loss:[0.465/0.465], time:3203.426 ms, lr:0.00000\n",
      "Train epoch time: 6557.858 ms, per step time: 3278.929 ms\n",
      "Epoch time: 6557.858 ms, per step time: 3278.929 ms, avg loss: 0.465\n",
      "Epoch:[232/240], step:[    1/    2], loss:[0.465/0.465], time:3113.704 ms, lr:0.00000\n",
      "Epoch:[232/240], step:[    2/    2], loss:[0.465/0.465], time:3066.890 ms, lr:0.00000\n",
      "Train epoch time: 6197.614 ms, per step time: 3098.807 ms\n",
      "Epoch time: 6198.615 ms, per step time: 3099.308 ms, avg loss: 0.465\n",
      "Epoch:[233/240], step:[    1/    2], loss:[0.465/0.465], time:3062.922 ms, lr:0.00000\n",
      "Epoch:[233/240], step:[    2/    2], loss:[0.464/0.465], time:3019.394 ms, lr:0.00000\n",
      "Train epoch time: 6101.332 ms, per step time: 3050.666 ms\n",
      "Epoch time: 6102.345 ms, per step time: 3051.173 ms, avg loss: 0.465\n",
      "Epoch:[234/240], step:[    1/    2], loss:[0.464/0.464], time:3280.942 ms, lr:0.00000\n",
      "Epoch:[234/240], step:[    2/    2], loss:[0.464/0.464], time:3271.956 ms, lr:0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch time: 6572.902 ms, per step time: 3286.451 ms\n",
      "Epoch time: 6573.904 ms, per step time: 3286.952 ms, avg loss: 0.464\n",
      "Epoch:[235/240], step:[    1/    2], loss:[0.465/0.465], time:3201.495 ms, lr:0.00000\n",
      "Epoch:[235/240], step:[    2/    2], loss:[0.465/0.465], time:3224.311 ms, lr:0.00000\n",
      "Train epoch time: 6444.823 ms, per step time: 3222.412 ms\n",
      "Epoch time: 6445.824 ms, per step time: 3222.912 ms, avg loss: 0.465\n",
      "Epoch:[236/240], step:[    1/    2], loss:[0.467/0.467], time:3192.538 ms, lr:0.00000\n",
      "Epoch:[236/240], step:[    2/    2], loss:[0.464/0.466], time:3139.458 ms, lr:0.00000\n",
      "Train epoch time: 6349.991 ms, per step time: 3174.995 ms\n",
      "Epoch time: 6349.991 ms, per step time: 3174.995 ms, avg loss: 0.466\n",
      "Epoch:[237/240], step:[    1/    2], loss:[0.465/0.465], time:2943.285 ms, lr:0.00000\n",
      "Epoch:[237/240], step:[    2/    2], loss:[0.465/0.465], time:3011.216 ms, lr:0.00000\n",
      "Train epoch time: 5972.518 ms, per step time: 2986.259 ms\n",
      "Epoch time: 5973.519 ms, per step time: 2986.759 ms, avg loss: 0.465\n",
      "Epoch:[238/240], step:[    1/    2], loss:[0.465/0.465], time:3427.264 ms, lr:0.00000\n",
      "Epoch:[238/240], step:[    2/    2], loss:[0.464/0.465], time:3179.009 ms, lr:0.00000\n",
      "Train epoch time: 6625.274 ms, per step time: 3312.637 ms\n",
      "Epoch time: 6626.275 ms, per step time: 3313.137 ms, avg loss: 0.465\n",
      "Epoch:[239/240], step:[    1/    2], loss:[0.464/0.464], time:3344.498 ms, lr:0.00000\n",
      "Epoch:[239/240], step:[    2/    2], loss:[0.465/0.464], time:3375.607 ms, lr:0.00000\n",
      "Train epoch time: 6945.975 ms, per step time: 3472.987 ms\n",
      "Epoch time: 6946.976 ms, per step time: 3473.488 ms, avg loss: 0.464\n",
      "train success\n"
     ]
    }
   ],
   "source": [
    "from mindvision.engine.loss import CrossEntropySmooth\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "set_seed(1)\n",
    "max_epoch = 100\n",
    "fixbase_epoch = 10\n",
    "batch_size_train = 32\n",
    "data_path = './datasets'\n",
    "height = 256\n",
    "width = 128\n",
    "\n",
    "num_classes, dataset1 = dataset_creator(root=data_path, height=height, width=width, batch_size_train=batch_size_train, mode='train')\n",
    "num_classes, dataset2 = dataset_creator(root=data_path, height=height, width=width, batch_size_train=batch_size_train, mode='train')\n",
    "num_batches = dataset1.get_dataset_size()\n",
    "\n",
    "net = create_osnet(num_classes=num_classes, pretrained=True, pretrained_dir='./pretrained_model')\n",
    "\n",
    "crit = CrossEntropySmooth(sparse=True,\n",
    "                          reduction=\"mean\",\n",
    "                          smooth_factor=0.1,\n",
    "                          classes_num=num_classes)\n",
    "\n",
    "lr = nn.cosine_decay_lr(0., 0.001, num_batches * max_epoch, num_batches,\n",
    "                                         max_epoch)\n",
    "time_cb = TimeMonitor(data_size=num_batches)\n",
    "\n",
    "net.stop_layer = ops.stop_gradient\n",
    "lr1 = lr[:fixbase_epoch * num_batches]\n",
    "opt1 = nn.Adam(net.classifier.trainable_params(), learning_rate=lr1, beta1=0.9,\n",
    "               beta2=0.99, weight_decay=0.0005)\n",
    "model1 = Model(network=net, optimizer=opt1, loss_fn=crit)\n",
    "loss_cb1 = LossMonitor(lr1)\n",
    "cb1 = [time_cb, loss_cb1]\n",
    "model1.train(fixbase_epoch, dataset1, cb1, dataset_sink_mode=True)\n",
    "\n",
    "net.stop_layer = ops.Identity()\n",
    "lr2 = lr[fixbase_epoch * num_batches:]\n",
    "loss_cb2 = LossMonitor(lr2)\n",
    "opt2 = nn.Adam(net.trainable_params(), learning_rate=lr2, beta1=0.9, beta2=0.99,\n",
    "               weight_decay=0.0005)\n",
    "model2 = Model(network=net, optimizer=opt2, loss_fn=crit)\n",
    "\n",
    "cb2 = [time_cb, loss_cb2]\n",
    "\n",
    "ckpt_append_info = [{\"epoch_num\": fixbase_epoch, \"step_num\": fixbase_epoch}]\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=10 * num_batches,\n",
    "                             keep_checkpoint_max=10, append_info=ckpt_append_info)\n",
    "ckpt_save_dir = 'output/checkpoint/market10'\n",
    "ckpt_cb = ModelCheckpoint(prefix=\"osnet\", directory=ckpt_save_dir, config=config_ck)\n",
    "cb2 += [ckpt_cb]\n",
    "\n",
    "model2.train(max_epoch-fixbase_epoch, dataset2, cb2, dataset_sink_mode=True)\n",
    "print(\"train success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b21d4",
   "metadata": {},
   "source": [
    "### 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8fae537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(19256:16812,MainProcess):2022-09-27-23:04:24.134.585 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n",
      "[WARNING] ME(19256:16812,MainProcess):2022-09-27-23:04:24.142.592 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded Market10\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     5 |       85 |         6\n",
      "  query    |     5 |       24 |         6\n",
      "  gallery  |     5 |       89 |         6\n",
      "  ----------------------------------------\n",
      "=> Loaded Market10\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     5 |       85 |         6\n",
      "  query    |     5 |       24 |         6\n",
      "  gallery  |     5 |       89 |         6\n",
      "  ----------------------------------------\n",
      "Extracting features from query set ...\n",
      "Done, obtained 24-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 89-by-512 matrix\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "ckpt=./output/checkpoint/market10/osnet-200_2.ckpt\n",
      "mAP: 54.4%\n",
      "CMC curve\n",
      "Rank-1  : 62.5%\n",
      "Rank-5  : 83.3%\n",
      "Rank-10 : 83.3%\n",
      "Rank-20 : 83.3%\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "def euclidean_squared_distance(input1, input2):\n",
    "    m, n = input1.shape[0], input2.shape[0]\n",
    "\n",
    "    shape_tensor1 = Tensor(np.zeros((m, n), dtype=np.float32))\n",
    "    shape_tensor2 = Tensor(np.zeros((n, m), dtype=np.float32))\n",
    "    op_pow = ops.Pow()\n",
    "\n",
    "    mat1 = op_pow(input1, 2).sum(axis=1, keepdims=True).expand_as(shape_tensor1)\n",
    "    mat2 = op_pow(input2, 2).sum(axis=1, keepdims=True).expand_as(shape_tensor2).T\n",
    "    distmat = mat1 + mat2\n",
    "    matmul = ops.MatMul(False, True)\n",
    "    cast = ops.Cast()\n",
    "    input1 = cast(input1, mindspore.float16)\n",
    "    input2 = cast(input2, mindspore.float16)\n",
    "    output = cast(matmul(input1, input2), mindspore.float32)\n",
    "    distmat = distmat - 2 * output\n",
    "\n",
    "    return distmat\n",
    "\n",
    "def eval_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank=50):\n",
    "    num_q, num_g = distmat.shape\n",
    "\n",
    "    if num_g < max_rank:\n",
    "        max_rank = num_g\n",
    "        print(\n",
    "            'Note: number of gallery samples is quite small, got {}'.\n",
    "            format(num_g)\n",
    "        )\n",
    "\n",
    "    indices = np.argsort(distmat, axis=1)\n",
    "    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n",
    "\n",
    "    # compute cmc curve for each query\n",
    "    all_cmc = []\n",
    "    all_AP = []\n",
    "    num_valid_q = 0. # number of valid query\n",
    "\n",
    "    for q_idx in range(num_q):\n",
    "        # get query pid and camid\n",
    "        q_pid = q_pids[q_idx]\n",
    "        q_camid = q_camids[q_idx]\n",
    "\n",
    "        # remove gallery samples that have the same pid and camid with query\n",
    "        order = indices[q_idx]\n",
    "        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)\n",
    "        keep = np.invert(remove)\n",
    "\n",
    "        # compute cmc curve\n",
    "        raw_cmc = matches[q_idx][\n",
    "            keep] # binary vector, positions with value 1 are correct matches\n",
    "        if not np.any(raw_cmc):\n",
    "            # this condition is true when query identity does not appear in gallery\n",
    "            continue\n",
    "\n",
    "        cmc = raw_cmc.cumsum()\n",
    "        cmc[cmc > 1] = 1\n",
    "\n",
    "        all_cmc.append(cmc[:max_rank])\n",
    "        num_valid_q += 1.\n",
    "\n",
    "        # compute average precision\n",
    "        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision\n",
    "        num_rel = raw_cmc.sum()\n",
    "        tmp_cmc = raw_cmc.cumsum()\n",
    "        tmp_cmc = [x / (i+1.) for i, x in enumerate(tmp_cmc)]\n",
    "        tmp_cmc = np.asarray(tmp_cmc) * raw_cmc\n",
    "        AP = tmp_cmc.sum() / num_rel\n",
    "        all_AP.append(AP)\n",
    "\n",
    "    assert num_valid_q > 0, 'Error: all query identities do not appear in gallery'\n",
    "\n",
    "    all_cmc = np.asarray(all_cmc).astype(np.float32)\n",
    "    all_cmc = all_cmc.sum(0) / num_valid_q\n",
    "    mAP = np.mean(all_AP)\n",
    "\n",
    "    return all_cmc, mAP\n",
    "\n",
    "\n",
    "class CustomWithEvalCell(nn.Cell):\n",
    "    def __init__(self, network):\n",
    "        super(CustomWithEvalCell, self).__init__(auto_prefix=False)\n",
    "        self._network = network\n",
    "\n",
    "    def construct(self, data):\n",
    "        outputs = self._network(data)\n",
    "        return outputs\n",
    "\n",
    "batch_size_test = 32\n",
    "checkpoint_file_path = \"./output/checkpoint/market10/osnet-200_2.ckpt\"\n",
    "\n",
    "num_train_classes, query_dataset = dataset_creator(root=data_path, height=height, width=width, batch_size_test=batch_size_test, mode='query')\n",
    "num_train_classes, gallery_dataset = dataset_creator(root=data_path, height=height, width=width, batch_size_test=batch_size_test, mode='gallery')\n",
    "\n",
    "net = create_osnet(num_train_classes)\n",
    "param_dict = load_checkpoint(checkpoint_file_path, filter_prefix='epoch_num')\n",
    "load_param_into_net(net, param_dict)\n",
    "\n",
    "net.set_train(False)\n",
    "net_eval = CustomWithEvalCell(net)\n",
    "\n",
    "def feature_extraction(eval_dataset):\n",
    "    f_, pids_, camids_ = [], [], []\n",
    "    for data in eval_dataset.create_dict_iterator():\n",
    "        imgs, pids, camids = data['img'], data['pid'], data['camid']\n",
    "        features = net_eval(imgs)\n",
    "        f_.append(features)\n",
    "        pids_.extend(pids.asnumpy())\n",
    "        camids_.extend(camids.asnumpy())\n",
    "    concat = ops.Concat(axis=0)\n",
    "    f_ = concat(f_)\n",
    "    pids_ = np.asarray(pids_)\n",
    "    camids_ = np.asarray(camids_)\n",
    "    return f_, pids_, camids_\n",
    "\n",
    "print('Extracting features from query set ...')\n",
    "qf, q_pids, q_camids = feature_extraction(query_dataset)\n",
    "print('Done, obtained {}-by-{} matrix'.format(qf.shape[0], qf.shape[1]))\n",
    "\n",
    "print('Extracting features from gallery set ...')\n",
    "gf, g_pids, g_camids = feature_extraction(gallery_dataset)\n",
    "print('Done, obtained {}-by-{} matrix'.format(gf.shape[0], gf.shape[1]))\n",
    "\n",
    "# if normalize_feature:\n",
    "#     l2_normalize = ops.L2Normalize(axis=1)\n",
    "#     qf = l2_normalize(qf)\n",
    "#     gf = l2_normalize(gf)\n",
    "\n",
    "print('Computing distance matrix with metric={} ...'.format('euclidean'))\n",
    "distmat = euclidean_squared_distance(qf, gf)\n",
    "distmat = distmat.asnumpy()\n",
    "\n",
    "print('Computing CMC and mAP ...')\n",
    "cmc, mAP = eval_rank(\n",
    "    distmat,\n",
    "    q_pids,\n",
    "    g_pids,\n",
    "    q_camids,\n",
    "    g_camids\n",
    ")\n",
    "\n",
    "print('** Results **')\n",
    "print('ckpt={}'.format(checkpoint_file_path))\n",
    "print('mAP: {:.1%}'.format(mAP))\n",
    "print('CMC curve')\n",
    "ranks = [1, 5, 10, 20]\n",
    "i = 0\n",
    "for r in ranks:\n",
    "    print('Rank-{:<3}: {:.1%}'.format(r, cmc[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fe871",
   "metadata": {},
   "source": [
    "## 引用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701b99b",
   "metadata": {},
   "source": [
    "[1] Liang Zheng*, Shengjin Wang, Liyue Shen*, Lu Tian*, Jiahao Bu, and Qi Tian. Person Re-identification Meets Image Search. Technical Report, 2015.\n",
    "\n",
    "[2] Zhou K, Yang Y, Cavallaro A, et al. Omni-scale feature learning for person re-identification[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 3702-3712."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore18_py37",
   "language": "python",
   "name": "mindspore18_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
